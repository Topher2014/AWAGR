{
  "title": "NVIDIA/Советы и приёмы",
  "url": "https://wiki.archlinux.org/title/NVIDIA/%D0%A1%D0%BE%D0%B2%D0%B5%D1%82%D1%8B_%D0%B8_%D0%BF%D1%80%D0%B8%D1%91%D0%BC%D1%8B",
  "sections": [
    {
      "title": "Исправление разрешения терминала",
      "level": 2,
      "content": "После перехода с драйвера nouveau вы можете заметить, что разрешение экрана в терминале уменьшилось. Для решения можно настроить разрешение через загрузчик.\n\nДля GRUB смотрите раздел GRUB/Tips and tricks#Setting the framebuffer resolution. [1] [2]\n\nДля systemd-boot установите console-mode в esp/loader/loader.conf, смотрите systemd-boot (Русский)#Настройка.\n\nДля rEFInd добавьте use_graphics_for +,linux в esp/EFI/refind/refind.conf. [3] Небольшая оговорка заключается в том, что это скроет отображение параметров ядра во время загрузки.\n\n"
    },
    {
      "title": "Использование ТВ-выхода",
      "level": 2,
      "content": "Смотрите Wikibooks:NVIDIA/TV-OUT.\n\n"
    },
    {
      "title": "X с телевизором (DFP) в качестве единственного дисплея",
      "level": 2,
      "content": "Если сервер X не обнаруживает подключенные мониторы, он откатывается на использование аналогового вывода (CRT-0). Это может стать проблемой при подключении ТВ через DVI в качестве основного монитора, если сервер X был запущен при выключенном ТВ или он был не подключен.\n\nДля принудительного использования DFP драйвером NVIDIA сохраните копию EDID в файловой системе там, где его сможет прочитать сервер X, вместо чтения EDID с ТВ/DFP.\n\nДля получения EDID запустите nvidia-settings, в нём внутри раздела нужной видеокарты (должен называться «GPU-0» или типа того) выберите пункт DFP («DFP-0» или что-то похожее), нажмите кнопку Acquire EDID... и сохраните файл куда-нибудь, например в /etc/X11/dfp0.edid.\n\nЕсли у вас не подключена мышь и клавиатура, EDID можно получить через командную строку. Запустите сервер X с нужным логированием для вывода блока EDID:\n\n```\n$ startx -- -logverbose 6\n```\n\nПосле окончания инициализации сервера X закройте его; журнал будет сохранён в /var/log/Xorg.0.log. Извлеките блок EDID с помощью nvidia-xconfig:\n\n```\n$ nvidia-xconfig --extract-edids-from-file=/var/log/Xorg.0.log --extract-edids-output-file=/etc/X11/dfp0.bin\n```\n\nОтредактируйте xorg.conf, добавив в секцию Device строки:\n\n```\nOption \"ConnectedMonitor\" \"DFP\"\nOption \"CustomEDID\" \"DFP-0:/etc/X11/dfp0.bin\"\n```\n\nОпция ConnectedMonitor принуждает драйвер распознавать DFP так, как будто он подключен. CustomEDID предоставляет данные EDID для устройства и говорит, что при загрузке ТВ/DFP как бы был подключен во время процесса запуска X.\n\nТаким образом можно автоматически запускать менеджер экрана при загрузке, иметь рабочий и настроенный экран для X до включения питания ТВ.\n\nЕсли вышеуказанные изменения не работают, в xorg.conf в секции Device вы можете попробовать удалить строку Option \"ConnectedMonitor\" \"DFP\" и добавить следующие строки:\n\n```\nOption \"ModeValidation\" \"NoDFPNativeResolutionCheck\"\nOption \"ConnectedMonitor\" \"DFP-0\"\n```\n\nОпция драйвера NVIDIA NoDFPNativeResolutionCheck предотвращает отключение всех режимов, которые не подходят к основному разрешению.\n\n"
    },
    {
      "title": "Разрешение без подключенных мониторов",
      "level": 2,
      "content": "В headless-режиме выставляется разрешение 640x480, которое будет использоваться в VNC или Steam Link. Чтобы выставить разрешение побольше, например 1920x1080, пропишите Virtual в подсекции Screen:\n\n```\nSection \"Screen\"\n   [...]\n   SubSection     \"Display\"\n       Depth       24\n       Virtual     1920 1080\n   EndSubSection\nEndSection\n```\n\n"
    },
    {
      "title": "Проверка источника питания",
      "level": 2,
      "content": "С помощью драйвера NVIDIA можно узнать текущий источник питания видеокарты. Для этого нужно получить значение параметра 'GPUPowerSource' с помощью утилиты nvidia-settings (0 — питание от сети, 1 — питание от батареи):\n\n```\n$ nvidia-settings -q GPUPowerSource -t\n```\n\n```\n1\n```\n\n"
    },
    {
      "title": "Прослушивание событий ACPI",
      "level": 2,
      "content": "Драйверы NVIDIA автоматически пытаются подключиться к демону acpid и получать уведомления о событиях ACPI (подключение/отключение источника питания, некоторые горячие клавиши и т.д.). Если соединение завершается неудачей, то X.org выведет следующее предупреждение:\n\n```\n~/.local/share/xorg/Xorg.0.log\n```\n\n```\nNVIDIA(0): ACPI: failed to connect to the ACPI event daemon; the daemon\nNVIDIA(0):     may not be running or the \"AcpidSocketPath\" X\nNVIDIA(0):     configuration option may not be set correctly.  When the\nNVIDIA(0):     ACPI event daemon is available, the NVIDIA X driver will\nNVIDIA(0):     try to use it to receive ACPI event notifications.  For\nNVIDIA(0):     details, please see the \"ConnectToAcpid\" and\nNVIDIA(0):     \"AcpidSocketPath\" X configuration options in Appendix B: X\nNVIDIA(0):     Config Options in the README.\n```\n\nВы можете запретить вывод этого сообщения, отключив опцию ConnectToAcpid в вашем конфигурационном файле:\n\n```\n/etc/X11/xorg.conf.d/20-nvidia.conf\n```\n\n```\nSection \"Device\"\n   ...\n   Driver \"nvidia\"\n   Option \"ConnectToAcpid\" \"0\"\n   ...\n EndSection\n```\n\nОднако если у вас ноутбук, то, возможно, более грамотным решением проблемы станет установка и запуск демона acpid.\n\n"
    },
    {
      "title": "Отображение температуры видеокарты в терминале",
      "level": 2,
      "content": "Существует три метода запроса температуры видеокарты. nvidia-settings требует использования X, nvidia-smi или nvclock — не требуют. Также обратите внимание, что nvclock в настоящее время не работает с новыми картами NVIDIA, такими как карты серии GeForce 200, а также интегрированными графическими решениями, такими как Zotac IONITX 8800GS.\n\n"
    },
    {
      "title": "nvidia-settings",
      "level": 3,
      "content": "Для отображения температуры графического ядра в терминале используйте nvidia-settings как указано ниже:\n\n```\n$ nvidia-settings -q gpucoretemp\n```\n\n```\nAttribute 'GPUCoreTemp' (hostname:0[gpu:0]): 49.\n    'GPUCoreTemp' is an integer attribute.\n    'GPUCoreTemp' is a read-only attribute.\n    'GPUCoreTemp' can use the following target types: GPU.\n```\n\nТемпература графического процессора этой платы 49 °C.\n\nПример того, как получить значение температуры для использования в утилитах вроде rrdtool или conky:\n\n```\n$ nvidia-settings -q gpucoretemp -t\n```\n\n```\n49\n```\n\n"
    },
    {
      "title": "nvidia-smi",
      "level": 3,
      "content": "nvidia-smi может читать температуру прямо с графического процессора без использования X, что удобно, например, при работе в Wayland или на сервере без графического интерфейса.\n\nОтображение температуры графического процессора с использованием nvidia-smi:\n\n```\n$ nvidia-smi\n```\n\n```\nWed Feb 28 14:27:35 2024\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce GTX 1660 Ti     Off |   00000000:01:00.0  On |                  N/A |\n|  0%   49C    P8              9W /  120W |     138MiB /   6144MiB |      2%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A    223179      G   weston                                        120MiB |\n+-----------------------------------------------------------------------------------------+\n```\n\nТолько температура:\n\n```\n$ nvidia-smi -q -d TEMPERATURE\n```\n\n```\n==============NVSMI LOG==============\n\nTimestamp                                 : Wed Feb 28 14:27:35 2024\nDriver Version                            : 550.54.14\nCUDA Version                              : 12.4\n\nAttached GPUs                             : 1\nGPU 00000000:01:00.0\n    Temperature\n        GPU Current Temp                  : 49 C\n        GPU T.Limit Temp                  : N/A\n        GPU Shutdown Temp                 : 95 C\n        GPU Slowdown Temp                 : 92 C\n        GPU Max Operating Temp            : 90 C\n        GPU Target Temperature            : 83 C\n        Memory Current Temp               : N/A\n        Memory Max Operating Temp         : N/A\n```\n\nПример того, как получить значение температуры для использования в утилитах вроде rrdtool или conky:\n\n```\n$ nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits\n```\n\n```\n49\n```\n\n"
    },
    {
      "title": "nvclock",
      "level": 3,
      "content": "Установите пакет nvclockAUR.\n\nМогут быть расхождения значений температуры между nvclock и nvidia-settings/nv-control. В соответствии с этим сообщением от автора nvclock (thunderbird), значения, которые выдаёт nvclock, более точные.\n\n"
    },
    {
      "title": "Включение разгона",
      "level": 3,
      "content": "- Разгон не работает, если Xorg запущен без прав суперпользователя. Запускайте Xorg с правами root.\n- Включение DRM kernel mode setting может привести к тому, что разгон станет недоступным, независимо от значения Coolbits.\n\nРазгон контролируется через опцию Coolbits в секции Device, позволяя использовать различные неподдерживаемые свойства:\n\n```\nOption \"Coolbits\" \"value\"\n```\n\n```\n# nvidia-xconfig --cool-bits=value\n```\n\nЗначение Coolbits - сумма его составляющих битов в двоичной системе исчисления. Типы битов:\n\n- 1 (bit 0) - Включает возможность разгона для старых (до архитектуры Fermi) ядер, вкладка Clock Frequencies в nvidia-settings.\n- 2 (bit 1) - Когда бит установлен, драйвер «будет пытаться инициализировать режим SLI, когда используются два графических процессора с разным количеством видеопамяти».\n- 4 (bit 2) - Включает ручное управление охлаждением графического процессора вкладка Thermal Monitor в nvidia-settings.\n- 8 (bit 3) - Включает возможность разгона на вкладке PowerMizer в nvidia-settings. Доступна с версии 337.12 для архитектур Fermi и новее. [4]\n- 16 (bit 4) - Включает возможность повышения напряжения через параметры командной строки nvidia-settings. Доступна с версии 346.16 для архитектур Fermi и новее.[5]\n\nЧтобы включить несколько свойств, сложите значения Coolbits. Например, чтобы включить возможности разгона и повышения напряжения для архитектуры Fermi, установите значение Option \"Coolbits\" \"24\".\n\nДокументация по Coolbits находится в /usr/share/doc/nvidia/html/xconfigoptions.html и здесь.\n\n"
    },
    {
      "title": "Настройка статического 2D/3D разгона",
      "level": 4,
      "content": "Для включения PowerMizer на максимальную производительность (без этого не будет работать VSync) используйте следующий параметр модуля ядра:\n\n```\n/etc/modprobe.d/nvidia.conf\n```\n\n```\noptions nvidia NVreg_RegistryDwords=\"PerfLevelSrc=0x2222\"\n```\n\n"
    },
    {
      "title": "Понижение максимальной частоты",
      "level": 4,
      "content": "На современных моделях видеокарт (как минимум на Ampere (NV170/GAXXX)[устаревшая ссылка 2025-04-06 ⓘ] и более новых) увеличение тактовых частот работает по-другому, и допустимый максимум тактовых частот устанавливается на наибольшее поддерживаемое значение при загрузке системы. Если это то, что вам нужно, то дополнительная настройка не требуется.\n\nНедостатком такого решения является снижение энергоэффективности. При увеличении тактовых частот нужно повышать напряжение для сохранения стабильности, что приводит к нелинейному росту энергопотребления, нагрева и шума вентилятора. Снижение допустимого максимума тактовых частот позволяет повысить эффективность.\n\nДля изменения можно использовать nvidia-smi от имени суперпользователя:\n\n- Просмотр поддерживаемых частот: $ nvidia-smi -q -d SUPPORTED_CLOCKS\n- Изменение частоты графического чипа на 1695 МГц: # nvidia-smi --lock-gpu-clocks=0,1695 --mode=1\n- Изменение частоты видеопамяти на 5001 МГц: # nvidia-smi --lock-memory-clocks=0,5001\n\n```\n$ nvidia-smi -q -d SUPPORTED_CLOCKS\n```\n\n```\n# nvidia-smi --lock-gpu-clocks=0,1695 --mode=1\n```\n\n```\n# nvidia-smi --lock-memory-clocks=0,5001\n```\n\nДля оптимизации энергоэффективности используйте nvidia-smi, чтобы проверить нагрузку видеокарты в любимой игре. Вертикальная синхронизация (VSync) должна быть включена. Снижение тактовой частоты увеличит нагрузку на видеокарту, поскольку она, будучи замедленной, будет тратить больше времени на рендеринг каждого кадра. Наилучшая эффективность достигается при использовании самых низких тактовых частот, при которых ещё не возникают подвисания, вызванные стопроцентной нагрузкой. Тогда каждый кадр будет отрисовываться достаточно быстро, чтобы не отставать от частоты обновления экрана.\n\nВ качестве примера можно привести использование указанных выше настроек вместо стандартных на RTX 3090 Ti при игре в Hitman 3 в 4K@60, что снижает энергопотребление на 30%, температуру с 75 до 63 градусов и скорость вращения вентилятора с 73% до 57%.\n\n"
    },
    {
      "title": "Сохранение настроек разгона",
      "level": 4,
      "content": "Как правило, изменения частоты и напряжения, сделанные через интерфейс nvidia-settings, не сохраняются, теряясь после перезагрузки. К счастью, существуют инструменты, предоставляющие интерфейс для разгона на проприетарном драйвере, способные сохранять настройки разгона пользователя и автоматически применять их при загрузке. Вот некоторые из них:\n\n- gweAUR — графический, применяет настройки при запуске сеанса рабочего стола\n- nvclockAUR и systemd-nvclock-unitAUR — графический, применяет настройки при загрузке системы\n- nvocAUR — текстовый, профили представляют собой конфигурационные файлы в /etc/nvoc.d/, применяет настройки при запуске сеанса рабочего стола\n\nПомимо них, можно прописывать значения атрибутов GPUGraphicsClockOffset и GPUMemoryTransferRateOffset с помощью команды nvidia-settings, добавив её в автозагрузку. Например:\n\n```\n$ nvidia-settings -a \"GPUGraphicsClockOffset[performance_level]=offset\"\n$ nvidia-settings -a \"GPUMemoryTransferRateOffset[performance_level]=offset\"\n```\n\nГде performance_level — наибольший номер «Performance Level», доступный для вашей видеокарты. Если видеокарт несколько, то нужно указать GPU ID: [gpu:gpu_id]GPUGraphicsClockOffset[performance_level]=offset.\n\n"
    },
    {
      "title": "Изменение лимита TDP",
      "level": 3,
      "content": "Современные видеокарты NVIDIA сбрасывают частоту, чтобы оставаться в пределах своего TDP и температуры. Для повышения производительности можно изменить предел TDP, что приведёт к повышению температуры и увеличению энергопотребления.\n\nНапример, чтобы установить предел энергопотребления на 160,30 Вт:\n\n```\n# nvidia-smi -pl 160.30\n```\n\nЧтобы установить предел во время загрузки системы:\n\n```\n/etc/systemd/system/nvidia-tdp.timer\n```\n\n```\n[Unit]\nDescription=Set NVIDIA power limit on boot\n\n[Timer]\nOnBootSec=5\n\n[Install]\nWantedBy=timers.target\n```\n\n```\n/etc/systemd/system/nvidia-tdp.service\n```\n\n```\n[Unit]\nDescription=Set NVIDIA power limit\n\n[Service]\nType=oneshot\nExecStart=/usr/bin/nvidia-smi -pl 160.30\n```\n\nИ включите юнит nvidia-tdp.timer.\n\n"
    },
    {
      "title": "Установка скорости вентилятора при входе",
      "level": 3,
      "content": "Вы можете выставить скорость вентилятора вашей графической карты с помощью консольного интерфейса nvidia-settings. Сначала убедитесь в том, что в вашем конфигурационном файле Xorg для опции Coolbits установлен бит 2.\n\nПоместите следующую строку в ваш файл xinitrc для управления вентилятором при запуске Xorg. Замените n на нужное вам значение скорости вентилятора в процентах.\n\n```\nnvidia-settings -a \"[gpu:0]/GPUFanControlState=1\" -a \"[fan:0]/GPUTargetFanSpeed=n\"\n```\n\nТакже вы можете указать и второй графический процессор путём увеличения счётчика графического процесора и вентилятора.\n\n```\nnvidia-settings -a \"[gpu:0]/GPUFanControlState=1\" -a \"[fan:0]/GPUTargetFanSpeed=n\" \\\n                -a \"[gpu:1]/GPUFanControlState=1\" -a  [fan:1]/GPUTargetFanSpeed=n\" &\n```\n\nЕсли вы используете менеджер входа вроде GDM или SDDM, вы можете создать файл настроек. Создайте ~/.config/autostart/nvidia-fan-speed.desktop и вставьте следующий текст. Снова измените n на нужное вам значение скорости вентилятора в процентах.\n\n```\n[Desktop Entry]\nType=Application\nExec=nvidia-settings -a \"[gpu:0]/GPUFanControlState=1\" -a \"[fan:0]/GPUTargetFanSpeed=n\"\nX-GNOME-Autostart-enabled=true\nName=nvidia-fan-speed\n```\n\nЧтобы можно было регулировать скорость вращения вентиляторов более чем одной видеокарты, выполните команду:\n\n```\n$ nvidia-xconfig --enable-all-gpus\n$ nvidia-xconfig --cool-bits=4\n```\n\n"
    },
    {
      "title": "Параметры модуля ядра",
      "level": 2,
      "content": "Некоторые параметры могут быть установлены как параметры модуля ядра, полный список можно получить, выполнив modinfo nvidia или посмотрев nv-reg.h. Смотрите также Gentoo:NVidia/nvidia-drivers#Kernel module parameters.\n\nНапример, включение следующих параметров включит PAT [7], что влияет на то, как выделяется память. PAT была впервые представлена в Pentium III [8] и поддерживается большинством более новых процессоров (Wikipedia:Page attribute table#Processors). Если ваша система может поддерживать эту функцию, это должно повысить производительность.\n\n```\n/etc/modprobe.d/nvidia.conf\n```\n\n```\noptions nvidia NVreg_UsePageAttributeTable=1\n```\n\nНа некоторых ноутбуках, чтобы разрешить изменения через nvidia-settings, необходимо включить этот параметр, иначе он будет отвечать «Setting applications clocks is not supported» и т. д.\n\n```\n/etc/modprobe.d/nvidia.conf\n```\n\n```\noptions nvidia NVreg_RegistryDwords=\"OverrideMaxPerf=0x1\"\n```\n\n"
    },
    {
      "title": "Сохранение видеопамяти в ждущем режиме",
      "level": 2,
      "content": "По умолчанию драйверы NVIDIA Linux сохраняют и восстанавливают в ждущем режиме только основные распределения видеопамяти. Как сказано в официальной документации:\n\nВ драйвере есть экспериментальная функция, позволяющая сохранять всю видеопамять (при наличии достаточного места на диске или в оперативной памяти) перед переходом в сон и восстанавливать её при пробуждении из сна.\n\nДля её включения добавьте параметр модуля ядра NVreg_PreserveVideoMemoryAllocations=1 для модуля nvidia и включите службы nvidia-suspend.service, nvidia-hibernate.service и nvidia-resume.service.\n\nПодробнее в официальной документации.\n\n- После внесения изменений не забудьте пересобрать образ initramfs, если вы используете ранний KMS.\n- По умолчанию содержимое видеопамяти сохраняется в каталог /tmp, в котором обычно примонтирована файловая система tmpfs. NVIDIA рекомендует указать другую файловую систему для наилучшей производительности. Это также необходимо, если размер оперативной памяти недостаточен для сохранения всей видеопамяти. Указать другое место сохранения можно с помощью параметра модуля ядра NVreg_TemporaryFilePath для модуля nvidia (например nvidia.NVreg_TemporaryFilePath=/var/tmp).\n- Выбранная вами файловая система должна поддерживать «unnamed temporary files» (например, ext4 или XFS) и иметь достаточно свободного места (то есть минимум на 5% больше общего объёма видеопамяти всех подключенных видеокарт NVIDIA). Узнать объём видеопамяти можно с помощью команды nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits.\n- Включение службы nvidia-resume.service необязательно, поскольку она делает то же самое, что уже автоматически делается через хук systemd-sleep(8) (/usr/lib/systemd/system-sleep/nvidia). Имейте в виду, что GDM с Wayland требует включение этой службы.\n\n"
    },
    {
      "title": "Драйвер persistence",
      "level": 2,
      "content": "Есть демон, который можно запускать при загрузке. В стандартной настольной среде с одной видеокартой демон не нужен и может создавать проблемы [9]. Смотрите раздел Driver Persistence документации NVIDIA для получения подробной информации.\n\nДля запуска демона persistence включите службу nvidia-persistenced.service. Для использования вручную смотрите документацию разработчика.\n\n"
    },
    {
      "title": "Принудительное использование YCbCr с субдискретизацией 4:2:0",
      "level": 2,
      "content": "Если вы столкнулись с ограничениями старых стандартов вывода, которые можно обойти использованием YUV 4:2:0, в драйвере NVIDIA есть недокументированная опция X11 для его принудительного использования:\n\n```\nOption \"ForceYUV420\" \"True\"\n```\n\nЭто позволит использовать более высокие разрешения или частоты обновления, но снизит качество изображения.\n\n"
    }
  ]
}