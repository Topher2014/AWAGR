{
  "title": "NFS (日本語)",
  "url": "https://wiki.archlinux.org/title/NFS_(%E6%97%A5%E6%9C%AC%E8%AA%9E)",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "関連記事\n\n- NFS/トラブルシューティング\n\nWikipedia より:\n\n- NFS は暗号化されません。機密情報を扱うときは Kerberos や Tinc などの暗号化プロトコルを使って NFS をトンネル化してください。\n- Samba とは異なり、NFS にはデフォルトでユーザー認証がありません。クライアントのアクセスは IP アドレスやホストネームで制限します。\n- NFS では、クライアントとサーバーの両方で ユーザー および/または ユーザーグループ ID が同じであることを期待しています（Kerberos を使用していない場合）。#idmapping を有効化するか、/etc/exports で anonuid/anongid と all_squash を一緒に使用して UID/GID を手動で上書きしてください。\n- NFS は POSIX ACLs をサポートしていません。NFS サーバーは引き続き ACL を強制しますが、クライアントはそれらを見たり変更したりすることができません。\n\n"
    },
    {
      "title": "目次",
      "level": 2,
      "content": "- 1 インストール\n- 2 サーバー設定 2.1 カスタムエクスポートルート 2.2 サーバーを起動する 2.3 特定のインターフェイスあるいは IP からのアクセスに NFS を制限 2.4 ファイアウォール設定 2.5 NFSv4 の ID マッピングが有効になっていることを確認\n- 3 クライアント設定 3.1 手動マウント 3.2 /etc/fstab を使う 3.3 systemd で /etc/fstab を使う 3.4 systemd ユニットとして 3.4.1 オートマウント 3.5 autofs を使う\n- 4 ヒントとテクニック 4.1 パフォーマンスチューニング 4.2 自動マウントの処理 4.2.1 Cron 4.2.2 systemd/タイマー 4.2.3 systemd で起動時にマウント 4.2.4 NetworkManager dispatcher を使う 4.3 TLS 暗号化 4.3.1 サーバー 4.3.2 クライアント\n- 5 トラブルシューティング\n- 6 参照\n\n- 2.1 カスタムエクスポートルート\n- 2.2 サーバーを起動する\n- 2.3 特定のインターフェイスあるいは IP からのアクセスに NFS を制限\n- 2.4 ファイアウォール設定\n- 2.5 NFSv4 の ID マッピングが有効になっていることを確認\n\n- 3.1 手動マウント\n- 3.2 /etc/fstab を使う\n- 3.3 systemd で /etc/fstab を使う\n- 3.4 systemd ユニットとして 3.4.1 オートマウント\n- 3.5 autofs を使う\n\n- 3.4.1 オートマウント\n\n- 4.1 パフォーマンスチューニング\n- 4.2 自動マウントの処理 4.2.1 Cron 4.2.2 systemd/タイマー 4.2.3 systemd で起動時にマウント 4.2.4 NetworkManager dispatcher を使う\n- 4.3 TLS 暗号化 4.3.1 サーバー 4.3.2 クライアント\n\n- 4.2.1 Cron\n- 4.2.2 systemd/タイマー\n- 4.2.3 systemd で起動時にマウント\n- 4.2.4 NetworkManager dispatcher を使う\n\n- 4.3.1 サーバー\n- 4.3.2 クライアント\n\n"
    },
    {
      "title": "インストール",
      "level": 2,
      "content": "クライアントとサーバーどちらでも必要なのは nfs-utils パッケージのインストールだけです。\n\nクライアント・サーバーの時計を一致させるために全てのノードで時刻同期デーモンを使うことが強く推奨されます。全てのノードで時計が正確でないと、NFS は望ましくない遅延を生じさせる可能性があります。\n\n"
    },
    {
      "title": "サーバー設定",
      "level": 2,
      "content": "グローバル設定オプションは /etc/nfs.conf で設定されます。単純な設定を使用するユーザーはこのファイルを編集する必要はありません。\n\nNFS サーバーは、共有するディレクトリのリストが必要で、/etc/exports または /etc/exports.d/*.exports に定義する必要があります（詳細は exports(5) を参照）。デフォルトでは、ディレクトリはそのパスのままエクスポートされます。例えば：\n\n```\n/etc/exports\n```\n\n```\n/data/music    192.168.1.0/24(rw)\n```\n\n上記の設定により、ディレクトリ /data/music は NFSv3 および NFSv4 で MyServer:/data/music としてマウント可能になります。\n\n"
    },
    {
      "title": "カスタムエクスポートルート",
      "level": 3,
      "content": "共有はいわゆる NFS ルートからの相対パスになります。セキュリティ上、NFS ルートを定義するときはサーバーのルートファイルシステム下の専用のディレクトリツリーを使用して、ユーザーからマウントポイントへのアクセスを制限すると良いでしょう。バインドマウントは、共有マウントポイントを ファイルシステム 上の実際のディレクトリにリンクするために使用されます。過去には NFSv4 で NFS ルートが必須でしたが、現在はオプションです（カーネル 2.6.33 および nfs-utils 1.2.2 から、仮想ルートが実装されています）。\n\n下の例では以下の設定を使用します:\n\n1. NFS ルートは /srv/nfs。\n1. エクスポートは /srv/nfs/music で /mnt/music にバインドマウントする。\n\n```\n# mkdir -p /srv/nfs/music /mnt/music\n# mount --bind /mnt/music /srv/nfs/music\n```\n\nサーバーを再起動してもマウントされるように、バインドマウントを fstab に追加:\n\n```\n/etc/fstab\n```\n\n```\n/mnt/music /srv/nfs/music  none   bind   0   0\n```\n\nCIDR によるアドレス指定またはホストネームを使ってマウントを許可するクライアントマシンを制限するには /etc/exports に以下のように共有ディレクトリを追加:\n\n```\n/etc/exports\n```\n\n```\n/srv/nfs        192.168.1.0/24(rw,fsid=root)\n/srv/nfs/music  192.168.1.0/24(rw,sync)\n/srv/nfs/home   192.168.1.0/24(rw,sync)\n/srv/nfs/public 192.168.1.0/24(ro,all_squash,insecure) desktop(rw,sync,all_squash,anonuid=99,anongid=99) # map to user/group - in this case nobody\n```\n\nNFSv4 を使用する場合、オプション fsid=root または fsid=0 は「ルート」エクスポートを示します。そのようなエクスポートが存在する場合、他のすべてのディレクトリはそれ以下でなければなりません。/etc/nfs.conf ファイルの rootdir オプションはこれに影響しません。fsid=0 エクスポートがない場合のデフォルトの動作は、NFSv3 と同じように動作することです。\n\n上記の例では、/srv/nfs がルートとして指定されているため、エクスポート /srv/nfs/music は NFSv4 を介して MyServer:/music としてマウント可能になります - ルートプレフィックスは省略されることに注意してください。\n\n- NFSv3 には必要ですが NFSv4 には必要ない crossmnt オプションは、crossmnt でマークされたファイルシステム上にマウントされた 全ての ファイルシステムにクライアントがアクセスできるようにします。クライアントはすべての子エクスポートを別々にマウントする必要がありません。ただし、異なるアドレス範囲で子が共有されている場合、これは望ましくないかもしれません。\n- crossmnt の代わりに、子エクスポートに nohide オプションを使用すると、クライアントがルートエクスポートをマウントするときに自動的にマウントされます。crossmnt と異なり、nohide は子エクスポートのアドレス範囲を尊重します。このオプションも NFSv3 固有であり、NFSv4 は常に nohide が有効であるかのように振る舞います。\n- insecure オプションは、クライアントが 1023 番以上のポートから接続できるようにします。（通常、ルートユーザーのみが低番号ポートを使用できるため、デフォルトで他のポートをブロックすることはアクセスへの表面的な障壁を作ります。実際には insecure オプションを省略しても含めても、セキュリティに有意な改善または悪化はありません。）\n- アスタリスク (*) を使用して、任意のインターフェースからのアクセスを許可します。\n\nサーバー実行中に /etc/exports を変更した場合は再度エクスポートしないと変更が適用されないので注意してください:\n\n```\n# exportfs -rav\n```\n\n現在ロードされているエクスポートの状態をより詳細に見るには、以下を使用する：\n\n```\n# exportfs -v\n```\n\n利用可能なオプションについて詳しくは exports(5) を参照してください。\n\n"
    },
    {
      "title": "サーバーを起動する",
      "level": 3,
      "content": "- NFSv3 および NFSv4 サービスを提供するには、nfs-server.service を開始して有効化します。\n- NFSv4 サービスのみを提供するには、nfsv4-server.service を開始して有効化します。\n\nプロトコルバージョン 4 のエクスポートを使用するユーザーは、不要なサービスが実行されないように、最低限 rpcbind.service と rpcbind.socket をマスクすることを望むでしょう。詳細は FS#76453 を参照してください。また、何らかの理由で引き込まれた nfs-server.service もマスクすることを検討してください。\n\n"
    },
    {
      "title": "特定のインターフェイスあるいは IP からのアクセスに NFS を制限",
      "level": 3,
      "content": "デフォルトでは nfs-server.service を起動すると /etc/exports とは関係なく全てのネットワークインターフェイスから接続を待機します。待機する IP あるいはホストネームを定義することで挙動を変更できます:\n\n```\n/etc/nfs.conf\n```\n\n```\n[nfsd]\nhost=192.168.1.123\n# Alternatively, you can use your hostname.\n# host=myhostname\n```\n\n変更を適用するには nfs-server.service を再起動してください。\n\n"
    },
    {
      "title": "ファイアウォール設定",
      "level": 3,
      "content": "ファイアウォールを通過してアクセスできるようにするには、デフォルト設定の場合 tcp と udp のポート 111, 2049, 20048 を開放する必要があります。rpcinfo -p を使ってサーバーで使用しているポートを確認してください。この設定を iptables でするには、/etc/iptables/iptables.rules を編集して以下の行を含めるようにしてください:\n\n```\n/etc/iptables/iptables.rules\n```\n\n```\n-A INPUT -p tcp -m tcp --dport 111 -j ACCEPT\n-A INPUT -p tcp -m tcp --dport 2049 -j ACCEPT\n-A INPUT -p tcp -m tcp --dport 20048 -j ACCEPT\n-A INPUT -p udp -m udp --dport 111 -j ACCEPT\n-A INPUT -p udp -m udp --dport 2049 -j ACCEPT\n-A INPUT -p udp -m udp --dport 20048 -j ACCEPT\n```\n\nNFSv3 と、上記の rpc.statd や lockd の固定ポートを使用している場合は、それらも設定に追加してください:\n\n```\n/etc/iptables/iptables.rules\n```\n\n```\n-A INPUT -p tcp -m tcp --dport 32765 -j ACCEPT\n-A INPUT -p tcp -m tcp --dport 32803 -j ACCEPT\n-A INPUT -p udp -m udp --dport 32765 -j ACCEPT\n-A INPUT -p udp -m udp --dport 32803 -j ACCEPT\n```\n\nv4 以上だけを使う構成の場合、開く必要があるのは tcp ポート 2049 だけです。したがって、必要な行は一行だけになります:\n\n```\n/etc/iptables/iptables.rules\n```\n\n```\n-A INPUT -p tcp -m tcp --dport 2049 -j ACCEPT\n```\n\n変更を適用するために、iptables サービスを再起動してください。\n\n"
    },
    {
      "title": "NFSv4 の ID マッピングが有効になっていることを確認",
      "level": 3,
      "content": "idmapd が動作していても、マッピングが完全には有効になっていないことがあります。/sys/module/nfsd/parameters/nfs4_disable_idmapping が N になっている場合、以下のコマンドを実行することで有効にできます:\n\n```\n# echo \"N\" | sudo tee /sys/module/nfsd/parameters/nfs4_disable_idmapping\n```\n\n変更を永続化するにはモジュールオプションで設定してください:\n\n```\n/etc/modprobe.d/nfsd.conf\n```\n\n```\noptions nfsd nfs4_disable_idmapping=0\n```\n\n"
    },
    {
      "title": "クライアント設定",
      "level": 2,
      "content": "NFSv4 で Kerberos を使用する場合、nfs-client.target も起動・有効化する必要があります。\n\n"
    },
    {
      "title": "手動マウント",
      "level": 3,
      "content": "NFSv3 の場合、次のコマンドを使ってサーバーのエクスポートされたファイルシステムを表示:\n\n```\n$ showmount -e servername\n```\n\nNFSv4 の場合、root NFS ディレクトリをマウントして利用できるマウントを確認:\n\n```\n# mount server:/ /mountpoint/on/client\n```\n\nそしてサーバーの NFS エクスポートルートは省略してマウント:\n\n```\n# mount -t nfs -o vers=4 servername:/music /mountpoint/on/client\n```\n\nマウントが失敗する場合はサーバーのエクスポートルートを含めて見て下さい (Debian/RHEL/SLES では必須、ディストリビューションによっては -t nfs ではなく -t nfs4):\n\n```\n# mount -t nfs -o vers=4 servername:/srv/nfs/music /mountpoint/on/client\n```\n\n"
    },
    {
      "title": "/etc/fstab を使う",
      "level": 3,
      "content": "クライアントを立ち上げたときにいつでも NFS 共有が使えるように、常に稼働させているサーバーでは fstab を利用すると便利です。/etc/fstab ファイルを編集して、設定に合わせて適切な行を追加してください。また、サーバーの NFS エクスポートルートは省略します。\n\n```\n/etc/fstab\n```\n\n```\nservername:/music  /mountpoint/on/client  nfs   rsize=8192,wsize=8192,timeo=14,_netdev 0 0\n```\n\nマウントオプションの説明は以下の通り:\n\n"
    },
    {
      "title": "systemd で /etc/fstab を使う",
      "level": 3,
      "content": "systemd の automount サービスを使う方法もあります。接続が遮断されたり、復帰した時に素早くネットワークデバイスを再マウントするため、_netdev よりも好ましいと思われます。さらに、autofs の問題も解決します、下の例を見て下さい:\n\n```\n/etc/fstab\n```\n\n```\nservername:/home  /mountpoint/on/client  nfs  noauto,x-systemd.automount,x-systemd.device-timeout=10,timeo=14,x-systemd.idle-timeout=1min 0 0\n```\n\nsystemd が fstab の変更に気づくようにクライアントを再起動する必要があります。もしくは、systemd をリロードして mountpoint-on-client.automount を再起動して /etc/fstab の設定を再読み込みしてください。\n\n- 上記の noauto はアクセスされるまで NFS 共有をマウントしません: いますぐに利用できるようにしたいときは auto を使って下さい。ネットワークが立ち上がってなかったり利用できないことが理由でマウントが失敗する問題が発生するときは、NetworkManager-wait-online.service を 有効にします: このサービスは有効化される前に network.target の全てのリンクが利用可能になることを保証します。\n- users マウントオプションはユーザーによるマウントを許可しますが、noexec などのオプションも含まれているので注意してください。\n- x-systemd.idle-timeout=1min オプションは NFS 共有が1分間使われなかったときに自動的にアンマウントします。ネットワークから突然切断する可能性があるノートパソコンなどで有用です。\n- NFS のせいでシャットダウンや再起動に時間がかかってしまうときは、NetworkManager-wait-online.service を有効化して NFS ボリュームがアンマウントされる前に NetworkManager が終了しないようにしてください。それでもシャットダウンが長すぎる場合 x-systemd.requires=network.target マウントオプションを追加してみてください。\n\n"
    },
    {
      "title": "systemd ユニットとして",
      "level": 3,
      "content": "/etc/systemd/system 内に新しい .mount ファイルを作成します。例：mnt-home.mount。詳細は systemd.mount(5) を参照してください。\n\nWhat= 共有へのパス\n\nWhere= 共有をマウントするパス\n\nOptions= 共有のマウントオプション\n\n- ネットワークマウントユニットは自動的に remote-fs-pre.target、network.target、および network-online.target に対して After 依存関係を取得し、nofail マウントオプションが設定されていない限り remote-fs.target に対して Before 依存関係を取得します。後者には Wants ユニットも追加されます。\n- Options に noauto を 追加 して、ブート時の自動マウントを防ぎます（他のユニットによって引き込まれない限り）。\n- サーバーの IP アドレスではなくホスト名を使用したい場合、After に nss-lookup.target を追加します。これにより、ユニットのテスト時には発生しないブート時のマウントエラーを回避できるかもしれません。\n\n```\n/etc/systemd/system/mnt-home.mount\n```\n\n```\n[Unit]\nDescription=Mount home at boot\n\n[Mount]\nWhat=172.16.24.192:/home\nWhere=/mnt/home\nOptions=vers=4\nType=nfs\nTimeoutSec=30\n\n[Install]\nWantedBy=multi-user.target\n```\n\nmnt-home.mount を使用するには、ユニットを開始し、システムブート時に実行するように有効化します。\n\n"
    },
    {
      "title": "オートマウント",
      "level": 4,
      "content": "共有を自動的にマウントするには、次のオートマウントユニットを使用できます：\n\n```\n/etc/systemd/system/mnt-home.automount\n```\n\n```\n[Unit]\nDescription=Automount home\n\n[Automount]\nWhere=/mnt/home\n\n[Install]\nWantedBy=multi-user.target\n```\n\nmnt-home.mount ユニットを無効化/停止し、mnt-home.automount を有効化/開始して、マウントパスにアクセスされた際に共有を自動マウントします。\n\n"
    },
    {
      "title": "autofs を使う",
      "level": 3,
      "content": "複数のマシンを NFS で接続したい場合は autofs を使うのが便利です。サーバーだけでなくクライアントにもなることができます。他の簡単な方法よりもこの方法が推奨される理由は、サーバーの電源が落とされた時に、クライアントがNFS 共有を見つけられないことについてエラーを投げないからです。詳しくは autofs#NFS ネットワークマウント を見て下さい。\n\n"
    },
    {
      "title": "パフォーマンスチューニング",
      "level": 3,
      "content": "Table content:\nこの記事またはセクションは情報が古くなっています。 理由: 32ビットや2.6 Linux カーネルに言及しています... (Discuss)\n\nクライアントの数が多いネットワークで NFS を使用する場合、デフォルトの NFS スレッド数を「8」から「16」やそれ以上に増やすことができます。これはサーバー/ネットワークの要件に応じて変わります：\n\n```\n/etc/nfs.conf\n```\n\n```\n[nfsd]\nthreads=16\n```\n\nNFS の性能を完全に発揮するには、ネットワーク設定にあわせて rsize や wsize マウントオプションを調整する必要があります。\n\n最近の Linux カーネル (2.6.18 以上) ではメモリの容量によって NFS サーバーが使用できる I/O のサイズ (最大ブロックサイズ) が変わります。最大は 1M (1048576バイト) で、NFS クライアントがより大きな rsize や wsize を必要としている場合でもサーバーの最大ブロックサイズが使われます [1]。nfsd を起動する前に /proc/fs/nfsd/max_block_size に書き込むことでサーバーのデフォルト最大ブロックサイズを変更できます。例えば、以下のコマンドは昔のデフォルトの IO サイズであった 32k に設定します:\n\n```\n# echo 32767 > /proc/fs/nfsd/max_block_size\n```\n\n変更を永続化するには systemd-tmpfile を作成してください:\n\n```\n/etc/tmpfiles.d/nfsd-block-size.conf\n```\n\n```\nw /proc/fs/nfsd/max_block_size - - - - 32768\n```\n\nTo mount with the increased rsize and wsize mount options:\n\nrsize と wsize を増やしたマウントオプションでマウントするには：\n\n```\n# mount -t nfs -o rsize=32768,wsize=32768,vers=4 servername:/srv/nfs/music /mountpoint/on/client\n```\n\nさらに、NFS プロトコルに違反するにもかかわらず、sync や sync,no_wdelay の代わりに async を設定すると、特に回転ディスクでは顕著なパフォーマンス向上が期待できるかもしれません。このオプションでエクスポートを設定し、exportfs -arv を実行して適用します。\n\n```\n/etc/exports\n```\n\n```\n/srv/nfs        192.168.1.0/24(rw,async,crossmnt,fsid=0)\n/srv/nfs/music  192.168.1.0/24(rw,async)\n```\n\n"
    },
    {
      "title": "自動マウントの処理",
      "level": 3,
      "content": "ローカルのワイヤレスネットワークから nfs 共有を使う必要があるノートパソコンでこの設定は役に立ちます。nfs ホストが到達できない状態になったとき、nfs 共有はアンマウントされ、hard マウントオプションを使っている際にシステムフリーズが起こらなくなります。https://bbs.archlinux.org/viewtopic.php?pid=1260240#p1260240 を参照。\n\nNFS のマウントポイントが /etc/fstab に正しく記述されていることを確認してください:\n\n```\n/etc/fstab\n```\n\n```\nlithium:/mnt/data          /mnt/data         nfs noauto,noatime,rsize=32768,wsize=32768 0 0\nlithium:/var/cache/pacman  /var/cache/pacman nfs noauto,noatime,rsize=32768,wsize=32768 0 0\n```\n\nnoauto マウントオプションは起動時に自動的に共有をマウントしないように systemd に命じます。これを設定していないとネットワーク上に共有が存在するかどうかわからないのに systemd が共有をマウントしようとしてブート中にブランクスクリーンで止まってしまいます。\n\nroot 以外のユーザー user で NFS 共有をマウントするには fstab にエントリを追加する必要があります。\n\ncron を使って NFS ホストが到達可能なチェックする auto_share スクリプトを作成:\n\n```\n/usr/local/bin/auto_share\n```\n\n```\n#!/bin/bash\n\nfunction net_umount {\n  umount -l -f $1 &>/dev/null\n}\n\nfunction net_mount {\n  mountpoint -q $1 || mount $1\n}\n\nNET_MOUNTS=$(sed -e '/^.*#/d' -e '/^.*:/!d' -e 's/\\t/ /g' /etc/fstab | tr -s \" \")$'\\n'b\n\nprintf %s \"$NET_MOUNTS\" | while IFS= read -r line\ndo\n  SERVER=$(echo $line | cut -f1 -d\":\")\n  MOUNT_POINT=$(echo $line | cut -f2 -d\" \")\n\n  # Check if server already tested\n  if [[ \"${server_ok[@]}\" =~ \"${SERVER}\" ]]; then\n    # The server is up, make sure the share are mounted\n    net_mount $MOUNT_POINT\n  elif [[ \"${server_notok[@]}\" =~ \"${SERVER}\" ]]; then\n    # The server could not be reached, unmount the share\n    net_umount $MOUNT_POINT\n  else\n    # Check if the server is reachable\n    ping -c 1 \"${SERVER}\" &>/dev/null\n\n    if [ $? -ne 0 ]; then\n      server_notok[${#Unix[@]}]=$SERVER\n      # The server could not be reached, unmount the share\n      net_umount $MOUNT_POINT\n    else\n      server_ok[${#Unix[@]}]=$SERVER\n      # The server is up, make sure the share are mounted\n      net_mount $MOUNT_POINT\n    fi\n  fi\ndone\n```\n\nスクリプトに実行権限を付与:\n\n```\n# chmod +x /usr/local/bin/auto_share\n```\n\ncron エントリか systemd タイマーを作成して、共有サーバーにアクセスできるか1分ごとに確認するようにしてください。\n\n"
    },
    {
      "title": "Cron",
      "level": 4,
      "content": "```\n# crontab -e\n```\n\n```\n* * * * * /usr/local/bin/auto_share\n```\n\n"
    },
    {
      "title": "systemd/タイマー",
      "level": 4,
      "content": "以下のユニットを作成:\n\n```\n# /etc/systemd/system/auto_share.timer\n```\n\n```\n[Unit]\nDescription=Check the network mounts\n\n[Timer]\nOnCalendar=*-*-* *:*:00\n\n[Install]\nWantedBy=timers.target\n```\n\n```\n# /etc/systemd/system/auto_share.service\n```\n\n```\n[Unit]\nDescription=Check the network mounts\n\n[Service]\nType=simple\nExecStart=/usr/local/bin/auto_share\n```\n\n作成したら auto_share.timer を有効化してください。\n\n"
    },
    {
      "title": "systemd で起動時にマウント",
      "level": 4,
      "content": "systemd のユニットファイルを使って起動時に NFS 共有をマウントすることも可能です。クライアントに NetworkManager がインストール・設定されている場合はユニットファイルは必要ありません。#NetworkManager dispatcher を見て下さい。\n\n```\n/etc/systemd/system/auto_share.service\n```\n\n```\n[Unit]\nDescription=NFS automount\nAfter=syslog.target network.target\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/usr/local/bin/auto_share\n\n[Install]\nWantedBy=multi-user.target\n```\n\nauto_share.service を有効化してください。\n\n"
    },
    {
      "title": "NetworkManager dispatcher を使う",
      "level": 4,
      "content": "上で説明している方法に加えて、ネットワークの状態が変わった時にスクリプトを実行するよう NetworkManager を設定することもできます。\n\nNetworkManager-dispatcher サービスを有効化・起動してください。\n\nネットワーク状態の変化にあわせてネットワーク上の共有をマウントする一番簡単な方法は auto_share スクリプトにシンボリックリンクを作成することです:\n\n```\n# ln -s /usr/local/bin/auto_share /etc/NetworkManager/dispatcher.d/30-nfs.sh\n```\n\nただし、特定の場合では、ネットワーク接続が無効になった後にアンマウントが実行され、KDE Plasma アプレットがフリーズしたりすることがあります。\n\n以下のスクリプトを使うことでネットワーク接続が切れる前に NFS 共有を安全にアンマウントすることができます:\n\n```\n/etc/NetworkManager/dispatcher.d/30-nfs.sh\n```\n\n```\n#!/bin/bash\n\n# Find the connection UUID with \"nmcli con show\" in terminal.\n# All NetworkManager connection types are supported: wireless, VPN, wired...\nWANTED_CON_UUID=\"CHANGE-ME-NOW-9c7eff15-010a-4b1c-a786-9b4efa218ba9\"\n\nif [[ \"$CONNECTION_UUID\" == \"$WANTED_CON_UUID\" ]]; then\n\n    # Script parameter $1: NetworkManager connection name, not used\n    # Script parameter $2: dispatched event\n    \n    case \"$2\" in\n        \"up\")\n            mount -a -t nfs4,nfs\n            ;;\n        \"pre-down\");&\n        \"vpn-pre-down\")\n            umount -l -a -t nfs4,nfs >/dev/null\n            ;;\n    esac\nfi\n```\n\nスクリプトに実行可能属性を付与:\n\n```\n# chmod +x /etc/NetworkManager/dispatcher.d/30-nfs.sh\n```\n\n/etc/NetworkManager/dispatcher.d/pre-down にシンボリックリンクを作成して pre-down イベントをキャッチ:\n\n```\n# ln -s /etc/NetworkManager/dispatcher.d/30-nfs.sh /etc/NetworkManager/dispatcher.d/pre-down.d/30-nfs.sh\n```\n\n上記のスクリプトは別の接続で別の共有をマウントするように修正することができます。\n\nNetworkManager#dispatcher を使って CIFS 共有のマウントを処理を参照。\n\n"
    },
    {
      "title": "TLS 暗号化",
      "level": 3,
      "content": "Linux 6.5 からは、xprtsec=tls マウントオプションを使用して NFS トラフィックを TLS で暗号化することができます。始めるには、クライアントとサーバーに ktls-utilsAUR パッケージをインストールし、以下の設定手順に従ってください。\n\n"
    },
    {
      "title": "サーバー",
      "level": 4,
      "content": "プライベートキーを作成し、サーバーの DNS 名を含む証明書を取得します（詳細は Transport Layer Security を参照）。これらのファイルをシステムの信頼ストアに追加する必要はありません。\n\n/etc/tlshd.conf を編集して、x509.certificate と x509.private_key に自分の値を使用してこれらのファイルを利用します。\n\n```\n/etc/tlshd.conf\n```\n\n```\n[authenticate.server]\nx509.certificate= /etc/nfsd-certificate.pem\nx509.private_key= /etc/nfsd-private-key.pem\n```\n\nそして、tlshd.service を開始して有効化します。\n\n"
    },
    {
      "title": "クライアント",
      "level": 4,
      "content": "前の手順で生成したサーバーの TLS 証明書をシステムの信頼ストアに追加します（詳細は トランスポート層セキュリティ を参照）。\n\ntlshd.service を開始して有効化します。\n\nこれで、サーバーの DNS 名を使用してサーバーをマウントすることができるはずです：\n\n```\n# mount -o xprtsec=tls servername.domain:/ /mountpoint/on/client\n```\n\nクライアント上の journalctl を確認すると、TLS ハンドシェイクが成功したことが表示されるはずです：\n\n```\n$ journalctl -b -u tlshd.service\n```\n\n```\nSep 28 11:14:46 client tlshd[227]: Built from ktls-utils 0.10 on Sep 26 2023 14:24:03\nSep 28 11:15:37 client tlshd[571]: Handshake with servername.domain (192.168.122.100) was successful\n```\n\n"
    },
    {
      "title": "トラブルシューティング",
      "level": 2,
      "content": "NFS/トラブルシューティングを参照してください。\n\n"
    },
    {
      "title": "参照",
      "level": 2,
      "content": "- NFS 共有の自動検出を可能にする Zeroconf 実装である Avahi も参照してください。\n- HOWTO: ディスクレスシステム\n- Microsoft Services for Unix NFS Client info\n- NFS on Snow Leopard\n- http://chschneider.eu/linux/server/nfs.shtml\n- How to do Linux NFS Performance Tuning and Optimization\n- Linux: Tune NFS Performance\n- Configuring an NFSv4-only Server\n\n"
    }
  ]
}