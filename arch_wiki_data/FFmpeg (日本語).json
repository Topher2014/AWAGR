{
  "title": "FFmpeg (日本語)",
  "url": "https://wiki.archlinux.org/title/FFmpeg_(%E6%97%A5%E6%9C%AC%E8%AA%9E)",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "関連記事\n\n- Flac を Mp3 に変換#FFmpeg を使う\n\nプロジェクトのホームページ より:\n\n"
    },
    {
      "title": "目次",
      "level": 2,
      "content": "- 1 インストール\n- 2 エンコードの例 2.1 スクリーンキャプチャ 2.2 ウェブカメラの録画 2.3 VOB から他のコンテナに 2.4 x264 2.4.1 ロスレス 2.4.2 Constant rate factor 2.4.3 ツーパス (超高品質) 2.4.4 動画の手ブレ補正 2.4.4.1 ファーストパス 2.4.4.2 セカンドパス 2.5 x265 2.6 シングルパス MPEG-2 (ニアロスレス) 2.7 字幕 2.7.1 抽出 2.7.2 ハードサブ 2.8 ボリュームゲイン 2.9 ボリュームノーマライゼーション 2.10 音声を抽出する 2.11 音声を除去する 2.12 ファイルを分割する 2.13 ハードウェアビデオアクセラレーション 2.13.1 VA-API 2.13.2 NVIDIA NVENC/NVDEC 2.13.3 Intel QuickSync (QSV) 2.13.4 AMD AMF 2.14 アニメーション GIF\n- 3 プリセットファイル 3.1 プリセットファイルを使う 3.1.1 libavcodec-vhq.ffpreset\n- 4 ヒントとテクニック 4.1 出力を簡略化 4.2 動画の再生時間を出力 4.3 ストリーム情報を JSON で出力 4.4 X フレームごとに動画のスクリーンショットを作成する\n- 5 参照\n\n- 2.1 スクリーンキャプチャ\n- 2.2 ウェブカメラの録画\n- 2.3 VOB から他のコンテナに\n- 2.4 x264 2.4.1 ロスレス 2.4.2 Constant rate factor 2.4.3 ツーパス (超高品質) 2.4.4 動画の手ブレ補正 2.4.4.1 ファーストパス 2.4.4.2 セカンドパス\n- 2.5 x265\n- 2.6 シングルパス MPEG-2 (ニアロスレス)\n- 2.7 字幕 2.7.1 抽出 2.7.2 ハードサブ\n- 2.8 ボリュームゲイン\n- 2.9 ボリュームノーマライゼーション\n- 2.10 音声を抽出する\n- 2.11 音声を除去する\n- 2.12 ファイルを分割する\n- 2.13 ハードウェアビデオアクセラレーション 2.13.1 VA-API 2.13.2 NVIDIA NVENC/NVDEC 2.13.3 Intel QuickSync (QSV) 2.13.4 AMD AMF\n- 2.14 アニメーション GIF\n\n- 2.4.1 ロスレス\n- 2.4.2 Constant rate factor\n- 2.4.3 ツーパス (超高品質)\n- 2.4.4 動画の手ブレ補正 2.4.4.1 ファーストパス 2.4.4.2 セカンドパス\n\n- 2.4.4.1 ファーストパス\n- 2.4.4.2 セカンドパス\n\n- 2.7.1 抽出\n- 2.7.2 ハードサブ\n\n- 2.13.1 VA-API\n- 2.13.2 NVIDIA NVENC/NVDEC\n- 2.13.3 Intel QuickSync (QSV)\n- 2.13.4 AMD AMF\n\n- 3.1 プリセットファイルを使う 3.1.1 libavcodec-vhq.ffpreset\n\n- 3.1.1 libavcodec-vhq.ffpreset\n\n- 4.1 出力を簡略化\n- 4.2 動画の再生時間を出力\n- 4.3 ストリーム情報を JSON で出力\n- 4.4 X フレームごとに動画のスクリーンショットを作成する\n\n"
    },
    {
      "title": "インストール",
      "level": 2,
      "content": "ffmpeg パッケージをインストールしてください。\n\n開発版は ffmpeg-gitAUR パッケージでインストールできます。可能な限り多くのオプション機能を有効化してビルドする ffmpeg-fullAUR も存在します。\n\n"
    },
    {
      "title": "エンコードの例",
      "level": 2,
      "content": "- パラメータを正しい順序で指定することが重要です (例: input、video、filters、audio、output)。順序を間違うと、パラメータがスキップされたり、FFmpeg が実行されなかったりする場合があります。\n- FFmpeg は、使用できる CPU スレッド数を自動的に選択するはずです。しかし、パラメータ -threads number を使って、使用できるスレッド数を強制したほうが良い場合もあります。\n\nFFmpeg のエンコード wiki と ffmpeg(1) § EXAMPLES を参照してください。\n\n"
    },
    {
      "title": "スクリーンキャプチャ",
      "level": 3,
      "content": "FFmpeg には x11grab と ALSA の仮想デバイスが含まれており、ユーザのディスプレイ全体と音声入力をキャプチャすることができます。\n\nスクリーンショットを撮って screen.png に保存するには:\n\n```\n$ ffmpeg -f x11grab -video_size 1920x1080 -i $DISPLAY -vframes 1 screen.png\n```\n\nここで、-video_size はキャプチャする領域のサイズを指定します。\n\nロスレスエンコードで音声なしのスクリーンキャストを撮って screen.mkv に保存するには:\n\n```\n$ ffmpeg -f x11grab -video_size 1920x1080 -framerate 25 -i $DISPLAY -c:v ffvhuff screen.mkv\n```\n\nここでは、Huffyuv コーデックが使用されます。このコーデックは高速ですが、ファイルサイズが大きくなります。\n\nロッシーエンコードで音声ありのスクリーンキャストを撮って screen.mp4 に保存するには:\n\n```\n$ ffmpeg -f x11grab -video_size 1920x1080 -framerate 25 -i $DISPLAY -f alsa -i default -c:v libx264 -preset ultrafast -c:a aac screen.mp4\n```\n\nここでは、x264 コーデックが最も高速なオプションで使用されます。他のコーデックを使用することもできます。(ディスクのパフォーマンスが十分でなかったり、エンコードが遅かったりで) 各フレームの書き込みが遅すぎる場合、フレームがドロップされ、動画出力がカクカクになります。\n\n動画ストリームをファイルとして保存する必要はないが、画面共有のために仮想ウェブカメラとして使う場合、v4l2loopback#FFmpeg を使って X11 をキャストする を参照してください。\n\n公式のドキュメントも参照してください。\n\n"
    },
    {
      "title": "ウェブカメラの録画",
      "level": 3,
      "content": "FFmpeg には video4linux2 と ALSA の入力デバイスが含まれています。これらにより、ウェブカメラと音声入力をキャプチャすることができます。\n\n以下のコマンドは、ウェブカメラから音声無しで動画を録画し webcam.mp4 に保存します。ウェブカメラが /dev/video0 として正しく認識されていると仮定します:\n\n```\n$ ffmpeg -f v4l2 -video_size 640x480 -i /dev/video0 -c:v libx264 -preset ultrafast webcam.mp4\n```\n\nここで、-video_size は、ウェブカメラからの許可されるイメージサイズの最大値を指定します。\n\n上記のコマンドは無音動画を出力します。音声ありでウェブカメラから動画を録画し webcam.mp4 に保存するには:\n\n```\n$ ffmpeg -f v4l2 -video_size 640x480 -i /dev/video0 -f alsa -i default -c:v libx264 -preset ultrafast -c:a aac webcam.mp4\n```\n\nここでは、x264 コーデックが最も高速なオプションで使用されます。他のコーデックを使用することもできます。(ディスクのパフォーマンスが十分でなかったり、エンコードが遅かったりで) 各フレームの書き込みが遅すぎる場合、フレームがドロップされ、動画出力がカクカクになります。\n\n公式のドキュメントも参照してください。\n\n"
    },
    {
      "title": "VOB から他のコンテナに",
      "level": 3,
      "content": "VOB ファイルを一つのストリームに連結して MPEG-2 にするには:\n\n```\n$ cat f0.VOB f1.VOB f2.VOB | ffmpeg -i - out.mp2\n```\n\n"
    },
    {
      "title": "ロスレス",
      "level": 4,
      "content": "ultrafast プリセットは最速のエンコードをするので素早い録画をしたいときに有用です (スクリーンキャストなど):\n\n```\n$ ffmpeg -i input -c:v libx264 -preset ultrafast -qp 0 -c:a copy output\n```\n\nultrafast プリセットの反対は veryslow で、ultrafast よりもエンコードが遅いかわりに出力するファイルのサイズが小さくなります:\n\n```\n$ ffmpeg -i input -c:v libx264 -preset veryslow -qp 0 -c:a copy output\n```\n\nどちらでも出力のクオリティは同じです。\n\n"
    },
    {
      "title": "Constant rate factor",
      "level": 4,
      "content": "出力する品質を指定したいときに使います。一般的に使われているのは最高の -crf 値で、これでも許容範囲内の画質になります。値が低いほど画質は高くなります。0はロスレス、18は見た目がロスレス、そして23がデフォルトの値です。賢明な値は18から28の範囲になります。一番遅い -preset を使うなら辛抱する必要があります。詳しくは x264 Encoding Guide を見て下さい。\n\n```\n$ ffmpeg -i video -c:v libx264 -tune film -preset slow -crf 22 -x264opts fast_pskip=0 -c:a libmp3lame -aq 4 output.mkv\n```\n\n-tune オプションを使うことでエンコードされるメディアの中身とタイプにあった設定にすることができます。\n\n"
    },
    {
      "title": "ツーパス (超高品質)",
      "level": 4,
      "content": "マルチパスの始めは動画の統計が記録されるため、音声が無効化されます:\n\n```\n$ ffmpeg -i video.VOB -an -vcodec libx264 -pass 1 -preset veryslow \\\n-threads 0 -b:v 3000k -x264opts frameref=15:fast_pskip=0 -f rawvideo -y /dev/null\n```\n\nコンテナの形式は出力ファイルの拡張子 (.mkv) から自動的に検出して変換されます:\n\n```\n$ ffmpeg -i video.VOB -acodec aac -b:a 256k -ar 96000 -vcodec libx264 \\\n-pass 2 -preset veryslow -threads 0 -b:v 3000k -x264opts frameref=15:fast_pskip=0 video.mkv\n```\n\n"
    },
    {
      "title": "動画の手ブレ補正",
      "level": 4,
      "content": "vbid.stab プラグインを使ってツーパスで手ブレ補正 (ビデオ安定化) を行います。\n\nファーストパスでは補正パラメータを記録してファイルに書き出します、または視覚分析のテスト動画を作成します。\n\n- 補正パラメータを記録してファイルだけに書き出す: $ ffmpeg -i input -vf vidstabdetect=stepsize=4:mincontrast=0:result=transforms.trf -f null -\n- 補正パラメータをファイルに書きだして、視覚分析用のテストビデオ \"output-stab\" を作成: $ ffmpeg -i input -vf vidstabdetect=stepsize=4:mincontrast=0:result=transforms.trf output-stab\n\n```\n$ ffmpeg -i input -vf vidstabdetect=stepsize=4:mincontrast=0:result=transforms.trf -f null -\n```\n\n```\n$ ffmpeg -i input -vf vidstabdetect=stepsize=4:mincontrast=0:result=transforms.trf output-stab\n```\n\nセカンドパスではファーストパスで作成した補正パラメータを解析して、それを使って \"output-stab_final\" を生成します。セカンドパスで他のフィルターを適用することもでき、変換を繰り返す必要をなくして画質を最大限保つことができます。下のコマンドでは以下のオプションを使っています:\n\n- unsharp: vid.stab の作者によって推奨されています。下の例ではデフォルトの 5:5:1.0:5:5:1.0 を使っています。\n- fade=t=in:st=0:d=4: 4秒間のフェードインをファイルの冒頭に挟みます。\n- fade=t=out:st=60:d=4: 動画の60秒目から4秒間のフェードアウトを挟みます。\n- -c:a pcm_s16le: XAVC-S コーデックは pcm_s16be で記録されロスレスの pcm_s16le に変換されます。\n\n```\n$  ffmpeg -i input -vf vidstabtransform=smoothing=30:interpol=bicubic:input=transforms.trf,unsharp,fade=t=in:st=0:d=4,fade=t=out:st=60:d=4 -c:v libx264 -tune film -preset veryslow -crf 8 -x264opts fast_pskip=0 -c:a pcm_s16le output-stab_final\n```\n\n"
    },
    {
      "title": "x265",
      "level": 3,
      "content": "以下の例は、パラメータを指定せずに libx265 を呼び出した場合のデフォルトを示します (Constant Rate Factor エンコード):\n\n```\nffmpeg -i input -c:v libx265 -crf 28 -preset medium -c:a libvorbis output.mp4\n```\n\n詳細は FFmpeg の H.265/HEVC Video Encoding Guide を参照してください。\n\n"
    },
    {
      "title": "シングルパス MPEG-2 (ニアロスレス)",
      "level": 3,
      "content": "DVD 標準のパラメータに FFmpeg を自動的に設定することができます。約 30 FPS の DVD MPEG-2 にエンコードするには:\n\n```\n$ ffmpeg -i video.VOB -target ntsc-dvd output.mpg\n```\n\n約 24 FPS の DVD MPEG-2 にエンコードするには:\n\n```\n$ ffmpeg -i video.VOB -target film-dvd output.mpg\n```\n\n"
    },
    {
      "title": "抽出",
      "level": 4,
      "content": "MPEG-2 や Matroska などのコンテナファイルに埋め込まれた字幕を抽出して、SRT や SSA、WebVTT などの字幕形式に変換することができます。[1]\n\n- ファイルに字幕ストリームが含まれているか確認してください:\n\n```\n$ ffprobe -hide_banner foo.mkv\n```\n\n```\n...\nStream #0:0(und): Video: h264 (High), yuv420p, 1920x800 [SAR 1:1 DAR 12:5], 23.98 fps, 23.98 tbr, 1k tbn, 47.95 tbc (default)\n  Metadata:\n  CREATION_TIME   : 2012-06-05 05:04:15\n  LANGUAGE        : und\nStream #0:1(und): Audio: aac, 44100 Hz, stereo, fltp (default)\n Metadata:\n CREATION_TIME   : 2012-06-05 05:10:34\n LANGUAGE        : und\n HANDLER_NAME    : GPAC ISO Audio Handler\nStream #0:2: Subtitle: ssa (default)\n```\n\n- foo.mkv には SSA の字幕が埋め込まれており、別のファイルに抽出することが可能です:\n\n```\n$ ffmpeg -i foo.mkv foo.ssa\n```\n\n字幕を望ましい形式 (例として SubRip) に保存するには -c:s srt を追加してください:\n\n```\n$ ffmpeg -i foo.mkv -c:s srt foo.srt\n```\n\n複数の字幕が存在する場合、-map key:stream パラメータを使用して抽出するストリームを指定する必要があります:\n\n```\n$ ffmpeg -i foo.mkv -map 0:2 foo.ssa\n```\n\n"
    },
    {
      "title": "ハードサブ",
      "level": 4,
      "content": "(FFmpeg wiki の記事の HowToBurnSubtitlesIntoVideo に基づく説明)\n\nハードサブは動画に字幕を焼きこむことになります。ハードサブは無効にすることが不可能で、言語の切り替えなどもできません。\n\n- foo.mpg に foo.ssa の字幕を重ねるには:\n\n```\n$ ffmpeg -i foo.mpg -vf subtitles=foo.ssa out.mpg\n```\n\n"
    },
    {
      "title": "ボリュームゲイン",
      "level": 3,
      "content": "ボリュームゲインは ffmpeg のフィルタ機能で変更できます。まず、-af または -filter:a を使って音声ストリームを選択し、次に、volume フィルタの後にそのストリームに対するゲインを指定してください。例えば:\n\n```\n$ ffmpeg -i input.flac -af volume=1.5 ouput.flac\n```\n\nここで、volume=1.5 によって 150% のボリュームゲインとなります。1.5 から 0.5 にすると、ボリュームが半分になります。ボリュームフィルタにはデシベル単位を渡すこともできます。volume=3dB とすると、ボリュームが 3dB 増え、volume=-3dB とすると 3dB 減ります。\n\n"
    },
    {
      "title": "ボリュームノーマライゼーション",
      "level": 3,
      "content": "loudnorm フィルタによるノーマライゼーションにより、平均ボリュームとピークボリュームを特定の値にすることができます。fmpeg のデフォルトの平均ラウドネス、ピークラウドネス、そしてレンジラウドネスの目標値 (それぞれ、-24 LUFS、-2 dBTP、7 LU) を使って、ファイルの知覚ラウドネスを正規化するには、以下のコマンドを使用してください:\n\n```\n$ ffmpeg -i input.flac -af loudnorm output.flac\n```\n\n別のラウドネスプロファイルを得るには、loudnorm フィルタのパラメータ i、tp、そして lra を使って、それぞれ integrated、true peak、loudness range を指定してください。例えば、デフォルトよりも高い知覚ラウドネスにするには:\n\n```\n$ ffmpeg -i input.flac -af loudnorm=i=-16:tp=-1.5:lra=11:print_format=summary output.flac\n```\n\nこの例では、オーディオファイルの入力ラウドネスと出力ラウドネスを表示するために print_format=summary も追加しています。\n\n"
    },
    {
      "title": "音声を抽出する",
      "level": 3,
      "content": "```\n$ ffmpeg -i video.mpg output.ext\n```\n\n```\n...\nInput #0, avi, from 'video.mpg':\n  Duration: 01:58:28.96, start: 0.000000, bitrate: 3000 kb/s\n    Stream #0.0: Video: mpeg4, yuv420p, 720x480 [PAR 1:1 DAR 16:9], 29.97 tbr, 29.97 tbn, 29.97 tbc\n    Stream #0.1: Audio: ac3, 48000 Hz, stereo, s16, 384 kb/s\n    Stream #0.2: Audio: ac3, 48000 Hz, 5.1, s16, 448 kb/s\n    Stream #0.3: Audio: dts, 48000 Hz, 5.1 768 kb/s\n...\n```\n\n多重化されている一番目の (-map 0:1) AC-3 でエンコードされた音声ストリームをファイルに抽出する:\n\n```\n$ ffmpeg -i video.mpg -map 0:1 -acodec copy -vn video.ac3\n```\n\n三番目の (-map 0:3) DTS 音声ストリームをビットレートが 192 kb/s でサンプリングレートが 96000 Hz の AAC ファイルに変換する:\n\n```\n$ ffmpeg -i video.mpg -map 0:3 -acodec aac -b:a 192k -ar 96000 -vn output.aac\n```\n\n-vn は動画ストリームの処理を無効にします。\n\n時間を指定して音声ストリームを抽出する:\n\n```\n$ ffmpeg -ss 00:01:25 -t 00:00:05 -i video.mpg -map 0:1 -acodec copy -vn output.ac3\n```\n\n-ss で開始時間を、-t で長さを指定します。\n\n"
    },
    {
      "title": "音声を除去する",
      "level": 3,
      "content": "1. 一番目の動画ストリーム (-map 0:0) と二番目の AC-3 音声ストリーム (-map 0:2) をコピーします。\n1. AC-3 音声ストリームをビットレートが 128 kb/s でサンプリングレートが 48000 Hz の2チャンネルの MP3 に変換します。\n\n```\n$ ffmpeg -i video.mpg -map 0:0 -map 0:2 -vcodec copy -acodec libmp3lame \\\n-b:a 128k -ar 48000 -ac 2 video.mkv\n```\n\n```\n$ ffmpeg -i video.mkv\n```\n\n```\n...\nInput #0, avi, from 'video.mpg':\n  Duration: 01:58:28.96, start: 0.000000, bitrate: 3000 kb/s\n    Stream #0.0: Video: mpeg4, yuv420p, 720x480 [PAR 1:1 DAR 16:9], 29.97 tbr, 29.97 tbn, 29.97 tbc\n    Stream #0.1: Audio: mp3, 48000 Hz, stereo, s16, 128 kb/s\n```\n\n"
    },
    {
      "title": "ファイルを分割する",
      "level": 3,
      "content": "copy コーデックを使うことでエンコーディングを変更せずにファイルの操作を行うことができます。例えば、次のコマンドであらゆるメディアファイルを簡単に2つに分けることが可能です:\n\n```\n$ ffmpeg -i file.ext -t 00:05:30 -c copy part1.ext -ss 00:05:30 -c copy part2.ext\n```\n\n"
    },
    {
      "title": "ハードウェアビデオアクセラレーション",
      "level": 3,
      "content": "ハードウェアアクセラレーション API を使用することで、エンコード/デコードのパフォーマンスを向上させることができます。しかし、特定の種類のコーデックしか使えませんし、場合によっては、ソフトウェアエンコードを使ったときと同じ結果が得られるとは限りません。\n\n"
    },
    {
      "title": "VA-API",
      "level": 4,
      "content": "Intel CPU (intel-media-driver か libva-intel-driver が必要) を使っている場合や、特定の AMD GPU でオープンソースの AMDGPU ドライバー (libva-mesa-driver が必要) を使っている場合、VA-API を使用してエンコードとデコードができます。\n\n利用可能なパラメータとサポートされているプラットフォームに関する情報は、FFmpeg のドキュメントや Libav のドキュメント[リンク切れ 2023-04-23] を参照してください。\n\nサポートされている H.264 コーデックを使用してエンコードする例:\n\n```\n$ ffmpeg -threads 1 -i file.ext -vaapi_device /dev/dri/renderD128 -vcodec h264_vaapi -vf format='nv12|vaapi,hwupload' output.mp4\n```\n\nクイックリファレンスとして、constant quality エンコードを行う例を以下に挙げます:\n\n```\n$ ffmpeg -vaapi_device /dev/dri/renderD128 -i input.mp4 -vf 'format=nv12,hwupload' -c:v hevc_vaapi -f mp4 -rc_mode 1 -qp 25 output.mp4\n```\n\nhevc_vaapi を使用する場合、-qp を 25 (視覚的に等価) からそれ以上 (28 から非常に小さな視覚的な損失が発生し始めます) の間で調整してください。h264_vaapi を使用する場合、18 (視覚的に等価) からそれ以上 (20 から非常に小さな視覚的な損失が発生し始めます) の間で調整してください。また、hevc_vaapi は h264_vaapi よりも 50% 高速にエンコードできるようです。\n\n"
    },
    {
      "title": "NVIDIA NVENC/NVDEC",
      "level": 4,
      "content": "プロプライエタリな NVIDIA ドライバを使用していて、nvidia-utils パッケージがインストールされている場合、NVENC と NVDEC をエンコード/デコードに使用できます。サポートされている GPU は 600 シリーズからです。詳細は ハードウェアビデオアクセラレーション#NVIDIA を参照してください。\n\nテクニックがこちらの古い gist に載っています。NVENC は CUDA と似ているため、ターミナルセッションからでも動作します。ハードウェア NVENC は Intel の VA-API エンコーダよりも数倍高速です。\n\n利用可能なオプションを表示するには以下のコマンドを実行してください (hevc_nvenc も使えます):\n\n```\n$ ffmpeg -help encoder=h264_nvenc\n```\n\n使用例:\n\n```\n$ ffmpeg -i source.ext -c:v h264_nvenc -rc constqp -qp 28 output.mkv\n```\n\n"
    },
    {
      "title": "Intel QuickSync (QSV)",
      "level": 4,
      "content": "Intel® Quick Sync Video は、Intel GPU のメディア処理機能を使用して高速なデコードとエンコードを行い、プロセッサが他のタスクを処理できるようにしてシステムの応答性を向上させます。\n\nこれを使用するには、libmfx ランタイム実装がインストールされている必要があります。libmfx は、ハードウェアプラットフォームに基づいて実行時に実装をロードするディスパッチャライブラリです。Broadwell から Rocket Lake までの GPU で実行する場合、このライブラリは intel-media-sdk をランタイム実装としてロードします。Alder Lake 及びそれ以降の GPU においては、libmfx は onevpl-intel-gpu をロードします。単一の Intel GPU を搭載しているシステムでは、ランタイム実装を変更したり選択したりできません。対応する実装は、ハードウェアに応じてインストールする必要があります。\n\n上記のランタイムをインストールしないと、以下のようなエラーが発生します:\n\n```\n[AVHWDeviceContext @ 0x558283838c80] Error initializing an MFX session: -3.\nDevice creation failed: -1313558101.\n```\n\nQuickSync の使用方法は FFmpeg Wiki で説明されています。libmfx を直接使わずに iHD ドライバか i965 ドライバで VA-API [2] を使用することが推奨されます。エンコード例は FFmpeg Wiki の Hybrid transcode セクションを、ドライバに関する指示は ハードウェアビデオアクセラレーション#VA-API の設定 を参照してください。\n\n"
    },
    {
      "title": "AMD AMF",
      "level": 4,
      "content": "AMD は、AMDGPU PRO プロプライエタリパッケージを使用して AMD Video Coding Engine (GPU エンコード) によって Linux で H264 のみのビデオエンコードを行うためのサポートを追加し、ffmpeg は AMF ビデオエンコードのサポートを追加しました。なので、h264_amf ビデオエンコーダを使ってエンコードするには、amf-amdgpu-proAUR が必要です。AMDGPU PRO パッケージによって提供されている ICD ファイルを環境変数でリンクする必要がある場合があります。そうしないと、ffmpeg はオープンな AMDGPU の ICD ファイルを使用してしまい、このビデオエンコーダを使用できません。エンコードを行うコマンドの例は以下のようになります:\n\n```\n$ VK_ICD_FILENAMES=/usr/share/vulkan/icd.d/amd_pro_icd64.json ffmpeg -hwaccel auto -vaapi_device /dev/dri/renderD128 -i input.mkv -c:v h264_amf -rc 1 -b:v 8M h264_amf_8M.mp4\n```\n\nクイックリファレンスとして、constant quality エンコードを行う例を挙げましょう:\n\n```\n$ VK_ICD_FILENAMES=/usr/share/vulkan/icd.d/amd_pro_icd64.json ffmpeg -hwaccel auto -vaapi_device /dev/dri/renderD128 -i input.mp4 -c:v h264_amf -f mp4 -rc 0 -qp_b 22 -qp_i 22 -qp_p 22 -quality 2 output.mp4\n```\n\n3つの -qp_(b|i|p) を調整してください。18 にすると視覚的に等価で、22 から非常に小さな視覚的な損失が発生し始めます。\n\n"
    },
    {
      "title": "アニメーション GIF",
      "level": 3,
      "content": "一般に、アニメーション GIF は、画像品質が悪く、ファイルサイズが比較的大きく、音声サポートもないので、動画フォーマットとして素晴らしい選択肢とは言えません。しかし、ウェブでは依然として頻繁に使用されています。以下のコマンドを使うことで、動画をアニメーション GIF に変換することができます:\n\n```\n$ ffmpeg -i input.mp4 -vf \"fps=10,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse\" -loop -1 output.gif\n```\n\nパレットフィルタを使って高品質な GIF を生成する方法については、http://blog.pkh.me/p/21-high-quality-gif-with-ffmpeg.html を見てください。\n\n"
    },
    {
      "title": "プリセットファイル",
      "level": 2,
      "content": "デフォルトのプリセットファイルで ~/.ffmpeg を作成する:\n\n```\n$ cp -iR /usr/share/ffmpeg ~/.ffmpeg\n```\n\n新しいファイルを作成したりデフォルトのプリセットファイルを編集する:\n\n```\n~/.ffmpeg/libavcodec-vhq.ffpreset\n```\n\n```\nvtag=DX50\nmbd=2\ntrellis=2\nflags=+cbp+mv0\npre_dia_size=4\ndia_size=4\nprecmp=4\ncmp=4\nsubcmp=4\npreme=2\nqns=2\n```\n\n"
    },
    {
      "title": "プリセットファイルを使う",
      "level": 3,
      "content": "-vcodec の宣言の後に -vpre オプションを加えて下さい。\n\n"
    },
    {
      "title": "libavcodec-vhq.ffpreset",
      "level": 4,
      "content": "- libavcodec = vcodec/acodec の名前\n- vhq = 使用するプリセットの名前\n- ffpreset = FFmpeg プリセットの拡張子\n\n"
    },
    {
      "title": "出力を簡略化",
      "level": 3,
      "content": "以下のオプションを組み合わせて使うことで、出力の詳細さを好きなレベルまで減らすことができます:\n\n- -hide_banner: 著作権表示、ビルドオプション、そしてライブラリのバージョンが表示されなくなります\n- -loglevel: ログレベルを調整します (微調整オプションが利用できます)。例: -loglevel warning\n- -nostats: エンコードの進捗/統計が表示されなくなります\n\n"
    },
    {
      "title": "動画の再生時間を出力",
      "level": 3,
      "content": "```\n$ ffprobe -select_streams v:0 -show_entries stream=duration -of default=noprint_wrappers=1:nokey=1 file.ext\n```\n\n"
    },
    {
      "title": "ストリーム情報を JSON で出力",
      "level": 3,
      "content": "```\n$ ffprobe -v quiet -print_format json -show_format -show_streams file.ext\n```\n\n"
    },
    {
      "title": "X フレームごとに動画のスクリーンショットを作成する",
      "level": 3,
      "content": "```\n$ ffmpeg -i file.ext -an -s 319x180 -vf fps=1/100 -qscale:v 75 %03d.jpg\n```\n\n"
    },
    {
      "title": "参照",
      "level": 2,
      "content": "- FFmpeg documentation - 公式ドキュメント\n- FFmpeg Wiki - 公式 wiki\n- Encoding with the x264 codec - MEncoder ドキュメント\n- H.264 encoding guide - Avidemux wiki\n- Using FFmpeg - Linux how to pages\n- サポートしている音声・動画ストリームのリスト\n\n"
    }
  ]
}