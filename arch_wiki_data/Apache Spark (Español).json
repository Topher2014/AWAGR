{
  "title": "Apache Spark (Español)",
  "url": "https://wiki.archlinux.org/title/Apache_Spark_(Espa%C3%B1ol)",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Artículos relacionados\n\n- Hadoop\n\nNote: **2019-02-09** \n\nApache Spark es un framework de computación en clúster de código abierto desarrollado originalmente en el AMPLab de la UC Berkeley. En contraste con el paradigma MapReduce basado en el disco de dos etapas de Hadoop, las primitivas en memoria de Spark ofrecen un rendimiento hasta 100 veces mayor para ciertas aplicaciones. Al permitir que los programas del usuario carguen datos en la memoria de un clúster y lo consulten repetidamente, Spark está bien adaptado a los algoritmos de aprendizaje automático.\n\n"
    },
    {
      "title": "Instalación",
      "level": 2,
      "content": "Instale el paquete apache-sparkAUR.\n\n"
    },
    {
      "title": "Configuración",
      "level": 2,
      "content": "Algunas variables de entorno se establecen en /etc/profile.d/apache-spark.sh.\n\nTable content:\nENV | Valor | Descripción\nPATH | $PATH:/opt/apache-spark/bin | Spark binaries\n\nEs posible que deba ajustar la variable de entorno PATH si su shell inhibe /etc/profile.d:\n\n```\nexport PATH=$PATH:/opt/apache-spark/bin\n```\n\n"
    },
    {
      "title": "Habilitar el soporte de R",
      "level": 2,
      "content": "El paquete R de sparkR se distribuye con el paquete pero no se compila durante la instalación. Para conectarse a Spark desde R, primero debe compilar el paquete ejecutando\n\n```\n# $SPARK_HOME/R/install-dev.sh\n```\n\ncomo se describe en $SPARK_HOME/R/README.md. También puede desear compilar la documentación del paquete siguiendo las instrucciones en $SPARK_HOME/R/DOCUMENTATION.md. Una vez que se haya compilado el paquete sparkR R, puede conectarse utilizando /usr/bin/sparkR.\n\n"
    }
  ]
}