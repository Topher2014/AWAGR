{
  "title": "Docker (Русский)",
  "url": "https://wiki.archlinux.org/title/Docker_(%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9)",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Ссылки по теме\n\n- systemd-nspawn (Русский)\n- Linux Containers\n- Vagrant\n\nDocker — утилита для упаковки, загрузки и запуска любых приложений в легковесных контейнерах.\n\n"
    },
    {
      "title": "Установка",
      "level": 2,
      "content": "Чтобы скачивать образы Docker и запускать контейнеры Docker, вам понадобится Docker Engine. Docker Engine включает в себя демон для управления контейнерами, а также интерфейс CLI docker. Установите пакет docker или разрабатываемую версию docker-gitAUR. Затем запустите/включите docker.service или docker.socket. Обратите внимание, что docker.service запускает службу при загрузке, тогда как docker.socket запускает docker при первом использовании, что может сократить время загрузки системы. Проверьте работу демона:\n\n```\n# docker info\n```\n\nОбратите внимание, что запуск службы Docker может завершиться сбоем, если имеется активное VPN-соединение. Это происходит из-за IP-конфликтов между сетевыми мостами и оверлейными сетями VPN и Docker. Если это так, попробуйте отключить VPN перед запуском службы Docker. Вы можете переподключить VPN сразу после этого. Вы также можете попытаться устранить конфликты сетей (смотрите решения [1] или [2]).\n\nЗатем проверьте, что запуск контейнеров работает. Следующая команда скачивает свежий образ Arch Linux и использует его для запуска программы Hello World в контейнере:\n\n```\n# docker run -it --rm archlinux bash -c \"echo hello world\"\n```\n\nЕсли требуется использовать команду docker от имени обычного пользователя, добавьте его в группу docker, перелогиньтесь и перезапустите службу docker.service.\n\n"
    },
    {
      "title": "Docker Compose",
      "level": 3,
      "content": "Docker Compose — это альтернативный интерфейс CLI для Docker Engine, который определяет свойства контейнеров с помощью YAML-файла docker-compose.yml вместо, например, скрипта с параметрами docker run. Это полезно для настройки служб, которые часто используются и/или имеют сложные конфигурации. Для использования установите пакет docker-compose.\n\n"
    },
    {
      "title": "Docker Desktop",
      "level": 3,
      "content": "Docker Desktop — это проприетарное настольное приложение, которое запускает Docker Engine внутри виртуальной машины Linux. Включены дополнительные функции, такие как кластер Kubernetes и сканер уязвимостей. Это приложение полезно для групп разработчиков программного обеспечения, которые разрабатывают контейнеры Docker с использованием macOS и Windows. Порт приложения для Linux является относительно новым и дополняет интерфейс командной строки Docker [5].\n\nЭкспериментальный пакет для Arch предоставляется непосредственно Docker. Подробнее в руководстве. К сожалению, он содержит файлы, которые конфликтуют с пакетом docker-compose, поэтому сначала вам необходимо удалить docker-compose, если он установлен. Но вы можете установить пакет docker-desktopAUR, который не конфликтует с существующими пакетами.\n\nКроме того, для запуска Docker Desktop ваша система должна соответствовать определённым требованиям, в частности, должна быть включена поддержка виртуализации KVM. Чтобы увидеть значок на панели задач в Gnome, потребуется gnome-shell-extension-appindicator.\n\nНаконец, поддержка совместного использования файлов требует сопоставления идентификаторов пользователей и групп через /etc/subuid и /etc/subgid. Дополнительные сведения см. в Инструкции по совместному использованию файлов Docker Desktop для Linux.\n\n"
    },
    {
      "title": "Использование",
      "level": 2,
      "content": "Docker состоит из нескольких компонентов:\n\n- Демон Docker (иногда его также называют Docker Engine) — это процесс, который запускается через docker.service. Он реализует Docker API и управляет контейнерами Docker.\n- Команда docker, которая позволяет пользователям взаимодействовать с Docker API через командную строку и управлять демоном Docker.\n- Контейнеры Docker — это изолированные (namespaced) процессы, которые запускаются и управляются демоном Docker по запросу через Docker API.\n\nОбычно пользователи используют Docker, выполняя команды docker, которые, в свою очередь, обращаются к демону Docker для выполнения действий, которые, в свою очередь, манипулируют контейнерами Docker. Понимание взаимосвязи между клиентом (docker), сервером (docker.service) и контейнерами важно для успешного администрирования Docker.\n\nОбратите внимание, что если демон Docker останавливается или перезапускается, все запущенные в данный момент контейнеры Docker тоже останавливаются или перезапускаются.\n\nТакже можно отправлять запросы к Docker API и управлять демоном Docker без использования команды docker. Смотрите документацию Docker API.\n\nПодробнее об использовании Docker можно почитать в Docker Getting Started guide.\n\n"
    },
    {
      "title": "Настройка",
      "level": 2,
      "content": "Демон Docker настраивается через файл настроек /etc/docker/daemon.json или через флаги командной строки в юните docker.service. Официальная документация рекомендует использовать файл настроек. Если вы хотите использовать флаги командной строки, используйте drop-in файлы, чтобы переопределить директиву ExecStart в docker.service.\n\nИнформация об опциях в daemon.json есть в документации.\n\n"
    },
    {
      "title": "Драйвер хранения",
      "level": 3,
      "content": "Драйвер хранения (storage driver) управляет хранением образов и контейнеров на вашем Docker-хосте. По умолчанию используется драйвер overlay2, который имеет хорошую производительность и является хорошим выбором для современных ядер Linux и файловых систем. Более старые драйверы devicemapper и aufs могут использоваться для совместимости со старыми ядрами Linux, но использовать их в Arch Linux вместо overlay2 смысла мало.\n\nПользователи Btrfs или ZFS могут использовать драйвер btrfs или zfs соответственно, преимущество которых в использовании возможностей, специфичных для файловой системы. Смотрите документацию драйвера btrfs и документацию драйвера zfs для более подробной информации.\n\n"
    },
    {
      "title": "Сокет демона",
      "level": 3,
      "content": "По умолчанию демон Docker принимает запросы Docker API через Unix-сокет /var/run/docker.sock. Это подходящий вариант в большинстве случаев.\n\nМожно настроить демон так, чтобы он дополнительно слушал TCP-сокет, что позволит получить удалённый доступ к Docker API с других компьютеров. [6] Это можно использовать, например, для того, чтобы команды docker, выполняемые на хосте, могли получить доступ к демону Docker, запущенному в виртуальной машине с Linux, например в виртуальной машине с Arch на хосте Windows или macOS.\n\nВ стандартном файле docker.service установлен флаг -H, и Docker не запустится, если опция присутствует одновременно во флагах и в файле /etc/docker/daemon.json. Поэтому самый простой способ изменить настройки сокета — использовать drop-in файл. Пример ниже добавляет TCP-сокет на порту 2376:\n\n```\n/etc/systemd/system/docker.service.d/docker.conf\n```\n\n```\n[Service]\nExecStart=\nExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376\n```\n\nДля применения изменений выполните daemon-reload и перезапустите службу docker.service.\n\n"
    },
    {
      "title": "HTTP-прокси",
      "level": 3,
      "content": "Настройка Docker для использования HTTP-прокси состоит из двух частей: настройка демона и настройка контейнеров.\n\n"
    },
    {
      "title": "Настройка демона для использования прокси",
      "level": 4,
      "content": "Смотрите документацию Docker.\n\n"
    },
    {
      "title": "Настройка контейнеров для использования прокси",
      "level": 4,
      "content": "Смотрите документацию Docker.\n\n"
    },
    {
      "title": "Настройка DNS",
      "level": 3,
      "content": "Документация Docker содержит подробную информацию о том, как работает DNS в контейнерах. Чаще всего используются те же DNS-серверы, которые используются на хосте.\n\nБольшинство DNS-серверов, запущенных на 127.0.0.0/8, не поддерживается из-за конфликтов между сетевыми пространствам имён хоста и контейнеров. Такие серверы убираются из файлов /etc/resolv.conf внутри контейнеров. Если в результате этого /etc/resolv.conf окажется пустым, то будет использоваться Google DNS.\n\nОсобым случаем является использование 127.0.0.53 в качестве единственного указанного DNS-сервера. В таком случае Docker предполагает наличие systemd-resolved и использует /run/systemd/resolve/resolv.conf.\n\nЕсли вы используете службу вроде dnsmasq, можно добавить виртуальный сетевой интерфейс с link-local адресом из блока 169.254.0.0/16 вместо 127.0.0.1.\n\n"
    },
    {
      "title": "Расположение образов",
      "level": 3,
      "content": "По умолчанию Docker образы расположены в /var/lib/docker. Они могут быть перемещены в другие разделы. Ниже в качестве примера рассматривается перемещение в /mnt/docker.\n\nДля начала остановите docker.service. Это также остановит все запущенные контейнеры и размонтирует все образы. После этого можно поместить файлы образов в нужное место, например, командой cp -r /var/lib/docker /mnt/docker.\n\nПосле этого в файле /etc/docker/daemon.json измените опцию data-root:\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"data-root\": \"/mnt/docker\"\n}\n```\n\nПерезапустите docker.service для применения изменений.\n\n"
    },
    {
      "title": "Небезопасные реестры",
      "level": 3,
      "content": "Если вы решите использовать самозаверенный сертификат для своего личного реестра, Docker откажется использовать его, пока вы не заявите, что доверяете ему. Например, чтобы разрешить использование образов из реестра myregistry.example.com:8443, измените опцию /etc/docker/daemon.json в файле /etc/docker/daemon.json:\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"insecure-registries\": [\n    \"my.registry.example.com:8443\"\n  ]\n}\n```\n\nПерезапустите docker.service для применения изменений.\n\n"
    },
    {
      "title": "IPv6",
      "level": 3,
      "content": "Чтобы включить поддержку IPv6 в Docker, необходимо выполнить несколько действий. Подробнее смотрите [7] и [8].\n\nСперва включите параметр ipv6 в файле /etc/docker/daemon.json и задайте определённую подсеть IPv6. В примерах ниже используется частная подсеть fd00::/80. Убедитесь, что используете подсеть не менее 80 бит, так как это позволит IPv6-адресу контейнера оканчиваться его MAC-адресом, что уменьшит проблемы с недействительностью кэша соседей NDP.\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"ipv6\": true,\n  \"fixed-cidr-v6\": \"fd00::/80\"\n}\n```\n\nПерезапустите docker.service для применения изменений.\n\nПосле этого, чтобы предоставить контейнерам доступ к сети хоста, необходимо решить проблемы с маршрутизацией, возникающие из-за использования частной подсети IPv6. Добавьте IPv6 NAT:\n\n```\n# ip6tables -t nat -A POSTROUTING -s fd00::/80 ! -o docker0 -j MASQUERADE\n```\n\nПосле этого IPv6 должен полноценно заработать. Проверить можно такой командой:\n\n```\n# docker run curlimages/curl curl -v -6 archlinux.org\n```\n\nЕсли вы используете firewalld, можно добавить подобное правило:\n\n```\n# firewall-cmd --zone=public --add-rich-rule='rule family=\"ipv6\" destination not address=\"fd00::1/80\" source address=\"fd00::/80\" masquerade'\n```\n\nДля ufw нужно сперва разрешить ipv6 forwarding, как описано в разделе Uncomplicated Firewall#Forward policy. Затем отредактируйте файл /etc/default/ufw, раскомментировав следующие строки:\n\n```\n/etc/ufw/sysctl.conf\n```\n\n```\nnet/ipv6/conf/default/forwarding=1\nnet/ipv6/conf/all/forwarding=1\n```\n\nПосле этого можно добавить правило iptables:\n\n```\n# ip6tables -t nat -A POSTROUTING -s fd00::/80 ! -o docker0 -j MASQUERADE\n```\n\nДля контейнеров docker, созданных с помощью docker-compose, может потребоваться установить значение enable_ipv6: true в разделе networks для соответствующей сети. Кроме того, может потребоваться настройка подсети IPv6. Смотрите [9] для более подробной информации.\n\n"
    },
    {
      "title": "Изоляция пользовательского пространства имён",
      "level": 3,
      "content": "По умолчанию процессы в контейнерах Docker запускаются в том же пользовательском пространстве имён, что и основной демон dockerd, то есть контейнеры не изолированы от него с помощью user_namespaces(7). Это позволяет процессу внутри контейнера получать доступ к настроенным ресурсам на хосте в соответствии с обычными правами доступа. Это обеспечивает максимальную совместимость, но создаёт риск безопасности в случае появления уязвимостей, связанных с повышением привилегий или побегом из контейнера (одна такая уязвимость была обнародована и исправлена в феврале 2019 года).\n\nВлияние такой уязвимости можно уменьшить с помощью изоляции пользовательского пространства имён — UID и GID внутри контейнеров будут сопоставляться с другим (как правило, непривилегированным) диапазоном UID/GID на хосте.\n\n- Демон dockerd всё равно будет запускаться от имени суперпользователя. Запуск Docker без прав суперпользователя — отдельная, не связанная с этим функция.\n- Процессы в контейнере запускаются от имени пользователя, указанного в директиве USER в Dockerfile, используемом для создания образа контейнера.\n- Все контейнеры используют и тот же диапазон UID/GID. Это сохраняет возможность совместного использования томов контейнерами.\n- Включение изоляции пользовательского пространства имён имеет ряд ограничений.\n- Включение изоляции пользовательского пространства имён фактически замаскирует существующие слои образов и контейнеров, а также другие объекты Docker в /var/lib/docker/, поскольку Docker необходимо настроить права на них. В официальной документации рекомендуется включать эту функцию на новой установке Docker, а не на существующей.\n\nВ файле /etc/docker/daemon.json измените опцию userns-remap. Значение default автоматически создаст пользователя и группу dockremap для использования с изоляцией пользовательского пространства имён.\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"userns-remap\": \"default\"\n}\n```\n\nНастройте /etc/subuid и /etc/subgid, указав имя пользователя/группы, начальные UID/GID и размеры диапазонов UID/GID. В примере ниже пользователю и группе dockremap назначается диапазон из 65536 UID и GID, начиная с 165536.\n\n```\n/etc/subuid\n```\n\n```\ndockremap:165536:65536\n```\n\n```\n/etc/subgid\n```\n\n```\ndockremap:165536:65536\n```\n\nПерезапустите docker.service для применения изменений.\n\nПосле этого все контейнеры будут по умолчанию работать в изолированном пользовательском пространстве имён. Это можно отключить для отдельных контейнеров с помощью флага --userns=host команды docker. Смотрите [10] для более подробной информации.\n\n"
    },
    {
      "title": "Запуск демона Docker без прав суперпользователя",
      "level": 3,
      "content": "Чтобы сам демон Docker запускался от имени обычного пользователя, установите пакет docker-rootless-extrasAUR.\n\nНастройте /etc/subuid и /etc/subgid, указав имя пользователя/группы, начальные UID/GID и размеры диапазонов UID/GID.\n\n```\n/etc/subuid\n```\n\n```\nимя_пользователя:165536:65536\n```\n\n```\n/etc/subgid\n```\n\n```\nимя_пользователя:165536:65536\n```\n\nВключите пользовательский юнит docker.socket; благодаря ему демон Docker будет автоматически запускаться при обращении к его сокету.\n\nНаконец, задайте переменную окружения, задающую путь к сокету демона Docker:\n\n```\n$ export DOCKER_HOST=unix://$XDG_RUNTIME_DIR/docker.sock\n```\n\n"
    },
    {
      "title": "Включение native overlay diff engine",
      "level": 3,
      "content": "Некоторые пользователи сообщают, что на их системах Docker не может использовать native overlay diff engine, что замедляет сборку образов. Если вы часто собираете образы, вы можете включить это, добавив параметры модуля ядра, как описано в [11]:\n\n```\n/etc/modprobe.d/disable-overlay-redirect-dir.conf\n```\n\n```\noptions overlay metacopy=off redirect_dir=off\n```\n\nПосле этого остановите docker.service и перезагрузите модуль overlay:\n\n```\n# modprobe -r overlay\n# modprobe overlay\n```\n\nЗатем можно снова запустить docker.service.\n\nДля проверки выполните docker info — в строке Native Overlay Diff должно быть true.\n\n"
    },
    {
      "title": "Arch Linux",
      "level": 3,
      "content": "Следующая команда скачивает x86_64 образ archlinux. Это урезанная версия ядра Arch без сети и т.д.\n\n```\n# docker pull archlinux\n```\n\nСмотрите также README.md.\n\nДля полноценного образа Arch, клонируйте репозиторий и создайте свой собственный образ.\n\n```\n$ git clone https://gitlab.archlinux.org/archlinux/archlinux-docker.git\n```\n\nУбедитесь, что пакеты devtools, fakechroot и fakeroot установлены.\n\nСборка базового образа:\n\n```\n$ make image-base\n```\n\n"
    },
    {
      "title": "Alpine Linux",
      "level": 3,
      "content": "Alpine Linux — популярный выбор для создания небольших образов, особенно для статически слинкованных программ. Следующая команда скачивает свежий образ Alpine Linux:\n\n```\n# docker pull alpine\n```\n\nAlpine Linux использует реализацию musl libc вместо glibc, используемой в большинстве дистрибутивов Linux. Поскольку Arch Linux использует glibc, существует ряд функциональных различий между хостом Arch Linux и контейнером Alpine Linux, которые могут повлиять на производительность и корректность работы программ. Список этих различий описан здесь.\n\nОбратите внимание, что динамически слинкованные программы, собранные на Arch Linux (или любой другой системе, использующей glibc), могут иметь ошибки и проблемы с производительностью при запуске на Alpine Linux (или любой другой системе, использующей другую libc). Примеры: [12], [13], [14].\n\n"
    },
    {
      "title": "Debian",
      "level": 3,
      "content": "Следующая команда скачивает свежий образ debian:\n\n```\n# docker pull debian\n```\n\nПолный список доступных тегов, включая стандартные и тонкие (slim) версии для каждого выпуска Debian, есть на странице Docker Hub.\n\n"
    },
    {
      "title": "Distroless",
      "level": 3,
      "content": "Google поддерживает образы distroless — минимальные образы без компонентов ОС, таких как менеджеры пакетов или оболочки, что позволяет создавать очень маленькие образы для упаковки программ.\n\nСписок образов и инструкции по их использованию с различными языками программирования есть в README на GitHub.\n\n"
    },
    {
      "title": "Получение IP-адреса запущенного контейнера",
      "level": 3,
      "content": "Чтобы получить IP адрес контейнера, выполните:\n\n```\n$ docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' <container-name OR id>\n```\n\n```\n172.17.0.37\n```\n\nДля каждого работающего контейнера имя и соответствующий IP-адрес могут быть перечислены для использования в /etc/hosts:\n\n```\n#!/usr/bin/env sh\nfor ID in $(docker ps -q | awk '{print $1}'); do\n    IP=$(docker inspect --format=\"{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\" \"$ID\")\n    NAME=$(docker ps | grep \"$ID\" | awk '{print $NF}')\n    printf \"%s %s\\n\" \"$IP\" \"$NAME\"\ndone\n```\n\n"
    },
    {
      "title": "Запуск графических программ внутри контейнера",
      "level": 3,
      "content": "В этом разделе описаны действия, необходимые для того, чтобы графические программы (в том числе те, которые используют OpenGL или Vulkan) могли работать на X-сервере хоста.\n\nВо-первых, в контейнере должны быть установлены правильные драйверы, совместимые с графическим оборудованием хоста. Процедура установки зависит от типа контейнера, но для контейнеров, основанных на образах Arch Linux, обратитесь к разделам OpenGL#Installation и Vulkan (Русский)#Установка для получения пакетов, специфичных для вашего оборудования.\n\nДалее нужно предоставить контейнеру доступ к X-серверу хоста. В однопользовательской среде это можно легко сделать, запустив Xhost на хосте, который добавляет несетевые локальные соединения в список контроля доступа:\n\n```\n$ xhost +local:\n```\n\nПосле этого нужно добавить следующие параметры к команде docker run:\n\n- -e \"DISPLAY=$DISPLAY\" для установки внутри контейнера переменной окружения DISPLAY, соответствующей дисплею хоста;\n- --mount type=bind,src=/tmp/.X11-unix,dst=/tmp/.X11-unix для доступа к сокету X-сервера изнутри контейнера;\n- --device=/dev/dri:/dev/dri для доступа к устройствам Direct Rendering Infrastructure хоста.\n\nДля проверки можно внутри контейнера запустить glxgears из пакета mesa-utils или vkcube из пакета vulkan-tools.\n\n"
    },
    {
      "title": "Запуск проектов Docker Compose при загрузке системы",
      "level": 3,
      "content": "Создайте юнит-шаблон для Docker Compose, параметром которого является название вашего проекта (смотрите systemd (Русский)#Написание файлов юнитов и systemd.service(5) § SERVICE TEMPLATES):\n\n```\n/etc/systemd/system/docker-compose@.service\n```\n\n```\n[Unit]\nDescription=%i service with docker compose\nRequires=docker.service\nAfter=docker.service\n\n[Service]\nWorkingDirectory=/opt/%i\nExecStartPre=-/usr/bin/docker compose pull\nExecStart=/usr/bin/docker compose up --remove-orphans\nExecStop=/usr/bin/docker compose down\nExecReload=/usr/bin/docker compose pull\nExecReload=/usr/bin/docker compose up --remove-orphans\n\n[Install]\nWantedBy=multi-user.target\n```\n\nЗатем для каждого проекта, который вы хотите запускать таким образом, создайте каталог /opt/название_проекта, содержащий файл Compose и другие необходимые для запуска файлы (например, .env). [15]\n\nПосле этого запустите/включите docker-compose@название_проекта.service.\n\n"
    },
    {
      "title": "Использование buildx для кросс-компиляции",
      "level": 3,
      "content": "Плагин buildx использует новый набор инструментов для сборки BuildKit. Установите пакет docker-buildx. Интерфейс buildx поддерживает сборку мультиплатформенных образов, в том числе для архитектур, отличных от архитектуры хоста.\n\nДля кросс-компиляции образов требуется QEMU. Чтобы настроить статическую сборку QEMU в Docker, смотрите информацию об использовании образа multiarch/qemu-user-static. В противном случае, чтобы настроить QEMU на хост-системе для использования с Docker, смотрите QEMU#Chrooting into arm/arm64 environment from x86_64. В любом случае система будет настроена на эмуляцию гостевой архитектуры в пользовательском режиме.\n\n```\n$ docker buildx ls\n```\n\n```\nNAME/NODE DRIVER/ENDPOINT STATUS  PLATFORMS\ndefault * docker\n  default default         running linux/amd64, linux/386, linux/arm64, linux/riscv64, linux/s390x, linux/arm/v7, linux/arm/v6\n```\n\n"
    },
    {
      "title": "С помощью NVIDIA Container Toolkit (рекомендуется)",
      "level": 4,
      "content": "Начиная с версии 19.03, графические процессоры NVIDIA поддерживаются в качестве устройств Docker. NVIDIA Container Toolkit ― рекомендуемый способ запуска контейнеров, использующих графические процессоры NVIDIA.\n\nУстановите пакет nvidia-container-toolkit и перезапустите Docker. Теперь вы можете запускать контейнеры Docker, использующие графические процессоры NVIDIA, с помощью параметра --gpus:\n\n```\n# docker run --gpus all nvidia/cuda:12.1.1-runtime-ubuntu22.04 nvidia-smi\n```\n\nУкажите, сколько графических процессоров разрешено в контейнере:\n\n```\n# docker run --gpus 2 nvidia/cuda:12.1.1-runtime-ubuntu22.04 nvidia-smi\n```\n\nУкажите, какие GPU следует использовать:\n\n```\n# docker run --gpus '\"device=1,2\"' nvidia/cuda:12.1.1-runtime-ubuntu22.04 nvidia-smi\n```\n\nили\n\n```\n# docker run --gpus '\"device=UUID-ABCDEF,1\"' nvidia/cuda:12.1.1-runtime-ubuntu22.04 nvidia-smi\n```\n\nЕсли при использовании вышеуказанных команд вы получаете ошибку типа Failed to initialize NVML: Unknown Error, вы можете попробовать более точно указать GPU:\n\n```\n# docker run --gpus all --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm --device /dev/nvidia0:/dev/nvidia0 nvidia/cuda:12.1.1-runtime-ubuntu22.04 nvidia-smi\n```\n\nУкажите возможности (\"graphics\", \"compute\", ...) контейнера (хотя это редко, если вообще когда либо используется таким образом):\n\n```\n# docker run --gpus all,capabilities=utility nvidia/cuda:12.1.1-runtime-ubuntu22.04 nvidia-smi\n```\n\nДля получения дополнительной информации смотрите документацию и руководство по установке.\n\nЕсли у вас установлен VirtualGL и вы получаете ошибку NVML, замените\n\n```\n/etc/nvidia-container-runtime/config.toml\n```\n\n```\n#user = \"root:video\"\n```\n\nна\n\n```\nuser = \"root:root\"\n```\n\nПодробнее об этой проблеме в NVIDIA/nvidia-docker на GitHub.\n\n"
    },
    {
      "title": "С помощью NVIDIA Container Runtime",
      "level": 4,
      "content": "Установите пакет nvidia-container-runtimeAUR[ссылка недействительна: package not found]. Затем, зарегистрируйте среду выполнения NVIDIA, отредактировав конфигурационный файл /etc/docker/daemon.json:\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"runtimes\": {\n    \"nvidia\": {\n      \"path\": \"/usr/bin/nvidia-container-runtime\",\n      \"runtimeArgs\": []\n    }\n  }\n}\n```\n\nи перезапустите docker.\n\nСреда выполнения также может быть зарегистрирована с помощью параметра командной строки dockerd:\n\n```\n# /usr/bin/dockerd --add-runtime=nvidia=/usr/bin/nvidia-container-runtime\n```\n\nПосле этого контейнеры с ускорением на графических процессорах могут быть запущены с помощью следующей команды:\n\n```\n# docker run --runtime=nvidia nvidia/cuda:9.0-base nvidia-smi\n```\n\nили (требуется Docker версии 19.03 или выше):\n\n```\n# docker run --gpus all nvidia/cuda:9.0-base nvidia-smi\n```\n\nСмотрите также README.md.\n\n"
    },
    {
      "title": "С помощью nvidia-docker (устарело)",
      "level": 4,
      "content": "nvidia-docker — обёртка над библиотекой среды исполнения NVIDIA Container Runtime, которая регистрирует среду выполнения NVIDIA по умолчанию и предоставляет команду nvidia-docker.\n\nЧтобы использовать nvidia-docker, установите пакет nvidia-dockerAUR[ссылка недействительна: package not found] и перезапустите Docker. Контейнеры с поддержкой NVIDIA GPU могут быть запущены, используя один из следующих методов:\n\n```\n# docker run --runtime=nvidia nvidia/cuda:9.0-base nvidia-smi\n```\n\n```\n# nvidia-docker run nvidia/cuda:9.0-base nvidia-smi\n```\n\nили (требуется Docker версии 19.03 или выше)\n\n```\n# docker run --gpus all nvidia/cuda:9.0-base nvidia-smi\n```\n\n"
    },
    {
      "title": "Образ Arch Linux с CUDA",
      "level": 4,
      "content": "Можно использовать следующий Dockerfile для создания собственного образа Arch Linux с CUDA. Он использует Dockerfile frontend syntax 1.2 для кэширования пакетов pacman на хосте. Перед запуском сборки нужно установить переменную окружения DOCKER_BUILDKIT=1.\n\n```\nDockerfile\n```\n\n```\n# syntax = docker/dockerfile:1.2\n\nFROM archlinux\n\n# установка пакетов\nRUN --mount=type=cache,sharing=locked,target=/var/cache/pacman \\\n    pacman -Syu --noconfirm --needed base base-devel cuda\n\n# настройка nvidia container runtime\n# https://github.com/NVIDIA/nvidia-container-runtime#environment-variables-oci-spec\nENV NVIDIA_VISIBLE_DEVICES all\nENV NVIDIA_DRIVER_CAPABILITIES compute,utility\n```\n\n"
    },
    {
      "title": "Удаление Docker и образов",
      "level": 2,
      "content": "Если вы хотите полностью удалить Docker, вам следует выполнить следующие шаги:\n\nВыдать список работающих контейнеров:\n\n```\n# docker ps\n```\n\nВыдать список всех контейнеров, запущенных на хосте для удаления:\n\n```\n# docker ps -a\n```\n\nОстановить работающий контейнер:\n\n```\n# docker stop <CONTAINER ID>\n```\n\nВыполнить команду kill для всё ещё работающих контейнеров:\n\n```\n# docker kill <CONTAINER ID>\n```\n\nУдалить все контейнеры, перечисленные по ID:\n\n```\n# docker rm <CONTAINER ID>\n```\n\nВыдать список всех образов Docker:\n\n```\n# docker images\n```\n\nУдалить все образы Docker по ID:\n\n```\n# docker rmi <IMAGE ID>\n```\n\nУдалить все образы, контейнеры, тома и сети, которые не связаны с контейнерами (висячие):\n\n```\n# docker system prune\n```\n\nЧтобы дополнительно удалить все остановленные контейнеры и все неиспользуемые образы (не только висячие), добавьте к команде флаг -a:\n\n```\n# docker system prune -a\n```\n\nУдалить все данные Docker (очистить каталог):\n\n```\n# rm -R /var/lib/docker\n```\n\n"
    },
    {
      "title": "docker0 Bridge не получает IP / нет доступа к Интернету в контейнерах при использовании systemd-networkd",
      "level": 3,
      "content": "Docker пытается включить пересылку (forwarding) IP-пакетов глобально, но по умолчанию systemd-networkd переопределяет глобальную настройку sysctl настройками конкретных сетевых профилей. Укажите IPForward=yes в сетевом профиле. Подробнее в разделе Раздача интернета#Разрешите пересылку пакетов.\n\nКогда systemd-networkd пытается управлять сетевыми интерфейсами, которые создал Docker, например, когда вы прописали Name=* в секции Match, это может привести к проблемам с подключением. Решить их можно сужением выбора интерфейсов, то есть избегайте использования Name=* или других масок, которые соответствуют сетевым интерфейсам Docker. Убедитесь, что networkctl list в столбце SETUP сообщает unmanaged для таких интерфейсов.\n\n- Вам может понадобится перезапускать docker.service каждый раз, когда вы выполняете перезапуск systemd-networkd.service или iptables.service.\n- Также имейте в виду, что nftables может блокировать соединения docker по умолчанию. Используйте nft list ruleset, чтобы проверить наличие блокирующих правил. nft flush chain inet filter forward временно удаляет все правила пересылки. Отредактируйте /etc/nftables.conf, чтобы сделать изменения постоянными. Не забудьте перезапустить nftables.service для применения изменений из файла. Подробнее о поддержке nftables в Docker: [16].\n\n"
    },
    {
      "title": "Слишком маленькое разрешённое количество процессов/потоков по умолчанию",
      "level": 3,
      "content": "Если вы столкнетесь с сообщениями об ошибках, похожими на следующие:\n\n```\n# e.g. Java\njava.lang.OutOfMemoryError: unable to create new native thread\n# e.g. C, bash, ...\nfork failed: Resource temporarily unavailable\n```\n\nто вам, возможно, необходимо изменить количество процессов, разрешённых systemd. Отредактируйте юнит docker.service следующим образом:\n\n```\n[Service]\nTasksMax=infinity\n```\n\nПодробнее смотрите DefaultLimitNPROC в systemd-system.conf(5) § OPTIONS и TasksMax в systemd.resource-control(5) § OPTIONS.\n\n"
    },
    {
      "title": "Error initializing graphdriver: devmapper",
      "level": 3,
      "content": "Если systemctl не запускает Docker и выдаёт ошибку:\n\n```\nError starting daemon: error initializing graphdriver: devmapper: Device docker-8:2-915035-pool is not a thin pool\n```\n\nПопробуйте выполнить следующие действия, чтобы устранить ошибку. Остановите службу, сделайте резервную копию /var/lib/docker/ (если это необходимо), удалите содержимое /var/lib/docker/ и попробуйте запустить службу. Смотрите описание проблемы на GitHub для более подробной информации.\n\n"
    },
    {
      "title": "Failed to create some/path/to/file: No space left on device",
      "level": 3,
      "content": "Если вы получаете сообщение об ошибке, подобное этому:\n\n```\nERROR: Failed to create some/path/to/file: No space left on device\n```\n\nпри создании или исполнении Docker образа, даже если у вас достаточно свободного места на диске, убедитесь, что:\n\n- Tmpfs отключен или имеет достаточно памяти. Docker может пытаться записать файлы в /tmp, но терпит неудачу из-за ограничений в использовании памяти, а не дискового пространства.\n- Если вы используете XFS, вы можете удалить опцию монтирования noquota из соответствующих записей в /etc/fstab (обычно тех, на которых находятся /tmp и/или /var/lib/docker). Для получения дополнительной информации обратитесь к Disk quota, особенно, если вы планируете использовать и изменить размер overlay2 Docker хранилища.\n- Варианты установки монтирования квоты XFS (uquota, gquota, prjquota, и т.д.) выдают ошибку при перемонтировании файловой системы. Чтобы включить квоту для корневой файловой системы, параметр монтирования должен быть передан как параметр ядра rootflags=. Впоследствии его не следует указывать среди параметров монтирования в /etc/fstab для корневой файловой системы (/).\n\n"
    },
    {
      "title": "Docker-machine не может создать виртуальные машины с драйвером virtualbox",
      "level": 3,
      "content": "Если docker-machine не может создать виртуальные машины с драйвером virtualbox и отображает следующую ошибку:\n\n```\nVBoxManage: error: VBoxNetAdpCtl: Error while adding new interface: failed to open /dev/vboxnetctl: No such file or directory\n```\n\nПерезагрузите virtualbox из командной строки с помощью команды vboxreload.\n\n"
    },
    {
      "title": "Запуск Docker ломает сетевой мост KVM",
      "level": 3,
      "content": "Проблема в том, что скрипты Docker добавляют некоторые правила iptables для блокировки пересылки на другие интерфейсы, кроме своего собственного. Это известная проблема.\n\nВ примерах ниже замените br0 на имя своего моста.\n\nСамое быстрое решение (но отключает все правила iptables, которые добавляет Docker, что может оказаться не тем, что вы хотите):\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"iptables\": false\n}\n```\n\nЕсли для KVM уже настроен сетевой мост, проблему можно решить, попросив docker использовать этот самый мост: [18]\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  \"bridge\": \"br0\"\n}\n```\n\nЕсли это не работает или вы предпочитаете решать проблему через iptables напрямую или через менеджер вроде UFW, добавьте следующее:\n\n```\niptables -I FORWARD -i br0 -o br0 -j ACCEPT\n```\n\nБолее подробные решения можно почитать здесь.\n\n"
    },
    {
      "title": "Ограничения на скачивание образов с Docker Hub",
      "level": 3,
      "content": "С 1 ноября 2020 года для загрузок из Docker Hub с анонимных и бесплатных аккаунтов включены лимиты (rate limiting). Подробнее в документации.\n\nЛимиты для неаутентифицированных пользователей отслеживаются по IP-адресу, а для аутентифицированных — по учётной записи.\n\nЕсли вам нужно превысить лимиты, вы можете либо использовать платный тарифный план, либо сделать зеркало нужных вам образов в другом реестре. Вы можете создать свой собственный реестр или использовать облачный хостинг, например Amazon ECR, Google Container Registry, Azure Container Registry или Quay Container Registry.\n\nЧтобы создать зеркало образа, используйте pull, tag и push в Docker CLI. Пример создания зеркала образа Nginx 1.19.3 в реестре cr.example.com:\n\n```\n$ docker pull nginx:1.19.3\n$ docker tag nginx:1.19.3 cr.example.com/nginx:1.19.3\n$ docker push cr.example.com/nginx:1.19.3\n```\n\nПосле этого можно скачивать или запускать образы с зеркала:\n\n```\n$ docker pull cr.example.com/nginx:1.19.3\n$ docker run cr.example.com/nginx:1.19.3\n```\n\n"
    },
    {
      "title": "iptables (legacy): unknown option \"--dport\"",
      "level": 3,
      "content": "Если возникает такая ошибка при запуске контейнера, установите iptables-nft вместо iptables (legacy) и перезагрузитесь [19].\n\n"
    },
    {
      "title": "\"Your password will be stored unencrypted\" при выполнении docker login",
      "level": 3,
      "content": "По умолчанию Docker попытается использовать pass или secretservice для хранения паролей в реестре. Если он не найдёт эти программы, то сохранит пароли в виде обычного текста (закодированного в base64) в файле $HOME/.docker/config.json и выведет следующее сообщение после успешного входа в систему:\n\n```\n$ WARNING! Your password will be stored unencrypted in /home/пользователь/.docker/config.json.\n```\n\nЕсли вы используете менеджер паролей, реализующий Secret Service Freedesktop DBUS API, например, kwallet из KDE или gnome-keyring из GNOME, вы можете установить пакет docker-credential-secretserviceAUR, чтобы хранить пароли в своём менеджере.\n\n"
    },
    {
      "title": "\"Could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network\"",
      "level": 3,
      "content": "Иногда при использовании большого числа проектов на Docker (например, при использовании docker-compose), может случиться так, что у вас закончатся IP-адреса для контейнеров, что приведёт к возникновению ошибки:\n\n```\nCould not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network\n```\n\nКак описано здесь, значения по умолчанию такие:\n\nTable content:\nТип | Размер по умолчанию | Пул по умолчанию\nlocal | /16 | 172.17.0.0/12\nlocal* | /20 | 192.168.0.0/16\n\nЭто можно легко исправить увеличением IP-пространства Docker через настройку default-address-pools в файле /etc/docker/daemon.json. Увеличьте первый диапазон с 16 до 24, а второй диапазон не трогайте, чтобы избежать коллизий в локальной сети:\n\n```\n/etc/docker/daemon.json\n```\n\n```\n{\n  ...\n  \"default-address-pools\" : [\n    {\n      \"base\" : \"172.17.0.0/12\",\n      \"size\" : 24\n    },\n    {\n      \"base\" : \"192.168.0.0/16\",\n      \"size\" : 24\n    }\n  ]\n}\n```\n\nПерезапустите docker.service для применения изменений.\n\nБолее подробную информацию можно почитать в статье The definitive guide to docker's default-address-pools option.\n\n"
    },
    {
      "title": "Смотрите также",
      "level": 2,
      "content": "- Официальный сайт\n- Arch Linux на docs.docker.com\n- Are Docker containers really secure? — opensource.com\n- Awesome Docker[устаревшая ссылка 2024-07-30 ⓘ]\n- Why A Privileged Container in Docker Is a Bad Idea\n\n"
    }
  ]
}